{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d849aa19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=JxEmltgf0yvQAsd_gxOWCrIuSoPMVIsyVflqiF8Qv5I&tc=HTFYgoYzP4jJ4P2qxsZxN7Bcx4slFpJ96cR0vVlINyI&cc=x4RO4JkbmKZNZo34nnMV4fY33FA6lbYBy8RT9cspKmw>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=JxEmltgf0yvQAsd_gxOWCrIuSoPMVIsyVflqiF8Qv5I&tc=HTFYgoYzP4jJ4P2qxsZxN7Bcx4slFpJ96cR0vVlINyI&cc=x4RO4JkbmKZNZo34nnMV4fY33FA6lbYBy8RT9cspKmw</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter verification code: 4/1AZEOvhXj29hfQslaT5eFKfpKFG_9OPcthsJYq5y7IZpdob3JC7gEyHhsRWY\n",
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "# if you want to have a pop up sign in method instead please uncomment  on ee.Authenticate and ee.Initialize, but comment on below\n",
    "\n",
    "import ee\n",
    "\n",
    "# Trigger the authentication flow. if you want to user json, please comment this\n",
    "ee.Authenticate()\n",
    "# Initialize the library.\n",
    "ee.Initialize()\n",
    "\n",
    "# here we try to use json api information instead (service account) - comment below if you use above methode\n",
    "#import ee\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "# uncomment this if you want to use json instead\n",
    "#service_account = 'iqbalpythonapi@bukit30project.iam.gserviceaccount.com'\n",
    "#credentials = ee.ServiceAccountCredentials(service_account, './bukit30project-4d92e5b46ea7.json')\n",
    "#ee.Initialize(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4975b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap#.foliumap as geemap\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Algorith outcome input (Forest Basemap (High baseline))\n",
    "algor_process = 'fcd_galcit'  #look below\n",
    "# Enter-input 'Sentinel' for prioritizing 'Sentinel' to get have Forest (High Baseline) and fill in the 10 years rule by Hansen,\n",
    "# Enter-input 'Hansen' for prioritizing TCL based forest (High Baseline), and 10 years rule and fill in by Sentinel for the uncertain areas (No Changes in areas that Crown cover)\n",
    "# Enter-input 'arief_hansen' for using empirical equation and get 10 years rule info with hansen after,\n",
    "# Enter-input 'hansen_arief' for prioritizing TCL based forest Hansen, and fill in by arief data in missing info\n",
    "# Enter-input 'fcd_galcit' for using fcd method and thermal index of landsat\n",
    "\n",
    "eval_process = False\n",
    "\n",
    "calc_areas = False\n",
    "\n",
    "exporting = True\n",
    "\n",
    "##### INPUT ###########################\n",
    "title_map = 'AOI_SRA_LANDSCAPE'\n",
    "\n",
    "#AOI File (SHP) - added shp_local: please make a folder in the main directory: shp_local and put here as an input (example) - shp local not publish to github\n",
    "AOIt_shp = './shp_local/AOI_SRA_LANDSCAPE.shp'\n",
    "AOIt_shp_plot = geemap.shp_to_ee(AOIt_shp)\n",
    "crs_input = 'EPSG:4326'\n",
    "\n",
    "# Edit this to False if there is no smaller AOI to overlay with\n",
    "small_aoi = True\n",
    "\n",
    "if small_aoi:\n",
    "    AOIsmall_shp = './shp_local/SRA_Concession.shp'\n",
    "    AOIsmall = geemap.shp_to_ee(AOIsmall_shp)\n",
    "    \n",
    "# edit this to False if there is no third layer smaller AOI to overlay with again\n",
    "smaller_aoi = True\n",
    "if smaller_aoi:\n",
    "    AOIsmaller_shp = './shp_local/Deliniate_FIX_GOZONE_new_plot.shp'\n",
    "    AOIsmaller = geemap.shp_to_ee(AOIsmaller_shp)\n",
    "\n",
    "################\n",
    "#for area id in shapefile that identified the data, and will converted into raster\n",
    "OID = 'id'  #IMPORTANT TO CHECK OID based on the column ID\n",
    "#############################################\n",
    "\n",
    "AOI = AOIt_shp_plot\n",
    "\n",
    "# Accuracy point Reference\n",
    "if eval_process:\n",
    "    ref_shp = './shp_local/ref_point_B30.shp' #### CHANGE THIS AS PER AOI LOCATION\n",
    "    #reference point input to gee object and geopandas\n",
    "    ref_point_loc = geemap.shp_to_ee(ref_shp)\n",
    "    gdf_ref = gpd.read_file(ref_shp)\n",
    "    #print(gdf_ref.head())\n",
    "\n",
    "######## HANSEN ##################\n",
    "# Hansen 10 years rule and Forest - Tree Cover Hansen\n",
    "#define tree cover minimum that classified as forest e.g., Indonesia > 30%, hence 30\n",
    "tree_cover_forest = 30 \n",
    "pixel_number = 3 #define minimum mapping unit classified as forest, 1 pixel for landsat 30mx30, 3 pixel is forest ~> 0.27 Ha\n",
    "year_start_loss = 20 #define start year to track as 10 years rule (e.g., 2012 to 2022 (track 10 years rule), hence 12. format= 00->2000, 12->2012)\n",
    "\n",
    "#CloudLess Images Sentinel\n",
    "START_DATE = '2022-1-1'   #Change this as perusal\n",
    "END_DATE = '2022-12-31'\n",
    "\n",
    "#Make an image out of the AOI area attribute -> convert featurecollection into raster (image) for overlaying tools\n",
    "AOI_img = AOI.filter(ee.Filter.notNull([OID])).reduceToImage(\n",
    "    properties= [OID],\n",
    "    reducer= ee.Reducer.first()\n",
    ")\n",
    "#Map.addLayer(AOI_img) #check if it works\n",
    "################\n",
    "\n",
    "#FOR FOREST DETECTION - Sentinel\n",
    "\n",
    "# Colors fo raster symbology\n",
    "water = '#3380cc' #Blue \n",
    "hi_forest = '#006837' #Strong green\n",
    "low_forest = '#3ea540' #Medium green\n",
    "grass_land = '#baf096' #Light green\n",
    "bare_land = '#ad8855' #Brown\n",
    "other = '#000000'\n",
    "\n",
    "#COEFICIENTS: These coeficients are orientative\n",
    "#and some tweak may be needed depending on the\n",
    "#location and case of study\n",
    "\n",
    "#NDWI water limit\n",
    "ndwi_hi_sentinel = 0.05 # for Sentinel\n",
    "ndwi_hi_landsat = 0.1 # for landsat\n",
    "ndwi_hi_planet = -0.2 # for Planet Labs\n",
    "\n",
    "#Bare soil index (BI), soil limit\n",
    "bi_hi = 2\n",
    "\n",
    "#NDVI high and low limits\n",
    "ndvi_lo = 0.25     #0.20 for L1C (suggested value)\n",
    "                   #0.25 for L2A (suggested value)\n",
    "ndvi_hi = 0.45     #0.40 for L1C (suggested value)\n",
    "                   #0.45 for L2A (suggested value)\n",
    "\n",
    "#Shadow index (SI) high and low limits\n",
    "si_lo = 0.92       #0.90 for L1C (suggested value) \n",
    "                   #0.92 for L2A (suggested value)\n",
    "si_hi = 0.95       #0.93 for L1C (suggested value) \n",
    "                   #0.95 for L2A (suggested value)\n",
    "#############################\n",
    "\n",
    "# output Band Names\n",
    "band_name_image = 'Class'\n",
    "\n",
    "\n",
    "# Threshold y (High Baseline ton) - arief et al\n",
    "y_threshold = 90\n",
    "\n",
    "# DEM\n",
    "type_DEM = 'srtm'\n",
    "\n",
    "alos = ee.Image('JAXA/ALOS/AW3D30_V1_1')\n",
    "srtm = ee.Image('USGS/SRTMGL1_003')\n",
    "\n",
    "# input scale based on the image property\n",
    "#pca_scale = image_corrected.projection().nominalScale()\n",
    "pca_scale = 60\n",
    "\n",
    "\n",
    "# Decide to use Thermal Index or not - if the result is poor because the availability of image for TI (Thermal Index noise) \n",
    "# please set to False\n",
    "TI_include = True\n",
    "\n",
    "## FCD Threshold\n",
    "high_forest = 70\n",
    "yrf_forest = 50\n",
    "shrub_grass = 30\n",
    "\n",
    "#revision of FCD threshold if TI is not included\n",
    "if TI_include == False:\n",
    "    high_forest = high_forest\n",
    "    yrf_forest = yrf_forest\n",
    "    shrub_grass = shrub_grass\n",
    "\n",
    "\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7c55786",
   "metadata": {},
   "outputs": [],
   "source": [
    "l4 = ee.ImageCollection(\"LANDSAT/LT04/C02/T1_L2\")\n",
    "l7 = ee.ImageCollection(\"LANDSAT/LE07/C02/T1_L2\")\n",
    "l9 = ee.ImageCollection(\"LANDSAT/LC09/C02/T1_L2\")\n",
    "l8 = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\")\n",
    "l5 = ee.ImageCollection(\"LANDSAT/LT05/C02/T1_L2\")\n",
    "\n",
    "# need to have this threshold for a map function of thermal index, to ensure the data available,\n",
    "#  if error 400 in TI or SSI data creation, please reduce the cloud cover\n",
    "cloud_cover_threshold = 50\n",
    "l4_raw = ee.ImageCollection(\"LANDSAT/LT04/C02/T1\")\n",
    "l7_raw = ee.ImageCollection(\"LANDSAT/LE07/C02/T1\")\n",
    "l9_raw = ee.ImageCollection(\"LANDSAT/LC09/C02/T1\")\n",
    "l8_raw = ee.ImageCollection(\"LANDSAT/LC08/C02/T1\")\n",
    "l5_raw = ee.ImageCollection(\"LANDSAT/LT05/C02/T1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b59d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PlanetNICFI = ee.ImageCollection(\"projects/planet-nicfi/assets/basemaps/asia\")\n",
    "filteredNicfi = PlanetNICFI.filterDate(START_DATE, END_DATE) \\\n",
    "                     .filterBounds(AOI)\n",
    "\n",
    "def scaling_planet(image):\n",
    "    sr_image = image.select(['R','G','B','N'], ['red','green', 'blue','nir']).multiply(0.0001)\n",
    "    return sr_image\n",
    "\n",
    "filtered_scaled = filteredNicfi.map(scaling_planet).median().clip(AOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d15db24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANDSAT\n"
     ]
    }
   ],
   "source": [
    "# additional conditioning input:\n",
    "if algor_process == 'fcd_galcit' and TI_include:\n",
    "    I_satellite = 'LANDSAT'\n",
    "elif algor_process == 'fcd_galcit' and TI_include == False:\n",
    "    print('choose Planet NICFI')\n",
    "    I_satellite = 'PlanetNicfi'\n",
    "else:\n",
    "    I_satellite = 'Sentinel'\n",
    "print(I_satellite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f530f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npixelCount = minArea.reduceRegion(\\n    reducer=ee.Reducer.count(),\\n    geometry=AOI.geometry(),\\n    scale=30,\\n    maxPixels=1e13\\n)\\nonePixel = forestSize.getNumber('treecover2000').divide(pixelCount.getNumber('treecover2000'))\\nminAreaUsed = onePixel.multiply(pixels)\\nprint('Minimum forest area used (ha)\\n ', minAreaUsed)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ Deforestation areas - TCL\n",
    "# hansen - updated version - global data\n",
    "gfc = ee.Image(\"UMD/hansen/global_forest_change_2022_v1_10\")\n",
    "\n",
    "#Canopy cover percentage (e.g. 30%), for Indonesia\n",
    "cc = ee.Number(tree_cover_forest)\n",
    "\n",
    "#Minimum forest area in pixels (e.g. 3 pixels, ~ 0.27 ha in this example).\n",
    "pixels = ee.Number(pixel_number)\n",
    "\n",
    "#Minimum mapping area for tree loss (usually same as the minimum forest area).\n",
    "lossPixels = pixels\n",
    "\n",
    "canopyCover = gfc.select(['treecover2000'])\n",
    "canopyCoverThreshold = canopyCover.gte(cc).selfMask()\n",
    "\n",
    "#Use connectedPixelCount() to get contiguous area.\n",
    "contArea = canopyCoverThreshold.connectedPixelCount()\n",
    "#Apply the minimum area requirement.\n",
    "minArea = contArea.gte(pixels).selfMask()\n",
    "\n",
    "prj = gfc.projection()\n",
    "scale = prj.nominalScale()\n",
    "ForestArea2000Hansen = minArea.reproject(prj.atScale(scale))\n",
    "\n",
    "Map = geemap.Map(center=(-3, 115), zoom=4)\n",
    "Map.centerObject(AOI, 10)\n",
    "Map.addLayer(ForestArea2000Hansen, {\n",
    "    'palette': ['#96ED89']\n",
    "}, 'tree cover: >= min canopy cover & area (light green)')\n",
    "\n",
    "#create visual boundary color only\n",
    "empty = ee.Image().byte()\n",
    "AOIm = empty.paint(AOI,0,10)\n",
    "\n",
    "#Map.addLayer(AOIm,{'palette': '#e043f3'},'AOI') #still buggy\n",
    "#Map.addLayer(AOIm,{},'AOI')\n",
    "\n",
    "'''\n",
    "forestArea = minArea.multiply(ee.Image.pixelArea()).divide(10000)\n",
    "forestSize = forestArea.reduceRegion(\n",
    "    reducer=ee.Reducer.sum(),\n",
    "    geometry=AOI.geometry(),\n",
    "    scale=30,\n",
    "    maxPixels=1e13\n",
    ")\n",
    "\n",
    "print(\n",
    "    'Year 2000 tree cover (ha) \\nmeeting minimum canopy cover and \\nforest area thresholds \\n ',\n",
    "    forestSize.get('treecover2000'))\n",
    "    \n",
    "'''\n",
    "\n",
    "'''\n",
    "pixelCount = minArea.reduceRegion(\n",
    "    reducer=ee.Reducer.count(),\n",
    "    geometry=AOI.geometry(),\n",
    "    scale=30,\n",
    "    maxPixels=1e13\n",
    ")\n",
    "onePixel = forestSize.getNumber('treecover2000').divide(pixelCount.getNumber('treecover2000'))\n",
    "minAreaUsed = onePixel.multiply(pixels)\n",
    "print('Minimum forest area used (ha)\\n ', minAreaUsed)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b827a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Visualized LANDSAT CLOUDLESS FROM HANSEN DATASET LAST YEAR\n",
    "LastImageLandsat = gfc.select(['last_b30', 'last_b40', 'last_b50', 'last_b70']).rename(['red', 'nir', 'swir1', 'swir2']).clip(AOI)\n",
    "Map.addLayer(LastImageLandsat, {'bands': ['swir2', 'nir', 'red'], 'min': 0, 'max': 600, 'gamma': 1.5 },\n",
    "                f'Landsat Hansen Last Year {END_DATE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec5ddc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FOR LANDSAT\n",
    "\n",
    "def filter_col(col, AOI, date):\n",
    "    return col.filterDate(date[0], date[1]).filterBounds(AOI).filter(ee.Filter.lte('CLOUD_COVER', cloud_cover_threshold))\n",
    "\n",
    "def cloud_mask_tm(image, sr=True):\n",
    "    qa = image.select('QA_PIXEL')\n",
    "    dilated = 1 << 1\n",
    "    cloud = 1 << 3\n",
    "    shadow = 1 << 4\n",
    "    mask = qa.bitwiseAnd(dilated).eq(0) \\\n",
    "        .And(qa.bitwiseAnd(cloud).eq(0)) \\\n",
    "        .And(qa.bitwiseAnd(shadow).eq(0))\n",
    "  \n",
    "    if sr:\n",
    "        optical_bands = image.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7'], ['blue', 'green', 'red', 'nir', 'swir1', 'swir2']) \\\n",
    "                                            .updateMask(mask) \\\n",
    "                                            .multiply(0.0000275).add(-0.2)\n",
    "        \n",
    "        \n",
    "        thermal_band = image.select(['ST_B6'], ['thermal']).updateMask(mask) \\\n",
    "                                            .multiply(0.00341802).add(149.0)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        optical_bands = image.select(['B1', 'B2', 'B3', 'B4', 'B5', 'B7'], ['blue', 'green', 'red', 'nir', 'swir1', 'swir2']) \\\n",
    "                                            .updateMask(mask) \\\n",
    "                                            .multiply(0.0001)\n",
    "        \n",
    "        thermal_band = image.select(['B6'], ['thermal']).updateMask(mask) \\\n",
    "                                            .multiply(0.0001)\n",
    "    \n",
    "    cloudM = mask.rename('cloudM')\n",
    "    \n",
    "    imageCloudMasked = image.addBands(optical_bands, None, True) \\\n",
    "                            .addBands(thermal_band, None, True)\n",
    "    \n",
    "    imageCloudMasked = imageCloudMasked.addBands(cloudM)\n",
    "    \n",
    "    return imageCloudMasked\n",
    "\n",
    "def cloud_mask_oli(image, sr=True):\n",
    "    qa = image.select('QA_PIXEL')\n",
    "    dilated = 1 << 1\n",
    "    cirrus = 1 << 2\n",
    "    cloud = 1 << 3\n",
    "    shadow = 1 << 4\n",
    "    mask = qa.bitwiseAnd(dilated).eq(0) \\\n",
    "        .And(qa.bitwiseAnd(cirrus).eq(0)) \\\n",
    "        .And(qa.bitwiseAnd(cloud).eq(0)) \\\n",
    "        .And(qa.bitwiseAnd(shadow).eq(0))\n",
    "\n",
    "    if sr:\n",
    "        #print('sr=True')\n",
    "        optical_bands = image.select(['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7'], ['blue', 'green', 'red', 'nir', 'swir1', 'swir2']) \\\n",
    "                        .updateMask(mask) \\\n",
    "                        .multiply(0.0000275).add(-0.2)\n",
    "\n",
    "        thermal_band = image.select(['ST_B10'], ['thermal']).updateMask(mask) \\\n",
    "                        .multiply(0.00341802).add(149.0)\n",
    "        \n",
    "    else:\n",
    "        optical_bands = image.select(['B2', 'B3', 'B4', 'B5', 'B6', 'B7'], ['blue', 'green', 'red', 'nir', 'swir1', 'swir2']) \\\n",
    "                        .updateMask(mask) #\\\n",
    "                        #.multiply(0.0001)\n",
    "\n",
    "        # image = detect_cloud_shadow(image)\n",
    "        \n",
    "        thermal_band = image.select(['B10'], ['thermal']) \\\n",
    "                        .updateMask(mask) #\\\n",
    "                        #.multiply(0.0001)\n",
    "            \n",
    "        #best_image_year = detect_cloud_shadow(best_image_year)\n",
    "        \n",
    "        AlB10 = ee.Number(image.get('RADIANCE_ADD_BAND_10'))\n",
    "        M1B10 = ee.Number(image.get('RADIANCE_MULT_BAND_10'))\n",
    "        \n",
    "        radiance = thermal_band.multiply(M1B10).add(AlB10)\n",
    "        \n",
    "        K_1 = ee.Number(image.get('K1_CONSTANT_BAND_10'))\n",
    "        K_2 = ee.Number(image.get('K2_CONSTANT_BAND_10'))\n",
    "        A = ee.Number(image.get('RADIANCE_ADD_BAND_10'))\n",
    "        M = ee.Number(image.get('RADIANCE_MULT_BAND_10'))\n",
    "\n",
    "        # Getting the Thermal Index - source??\n",
    "        TI = radiance.expression('(K_2) / log((K_1 / TEMP)+1)',{\n",
    "              'K_2': K_2,\n",
    "              'K_1': K_1,\n",
    "              'TEMP':radiance\n",
    "            }\n",
    "          ).rename('TI')\n",
    "        \n",
    "    \n",
    "    cloudM = mask.rename('cloudM')\n",
    "    \n",
    "    imageCloudMasked = image.addBands(optical_bands, None, True) \\\n",
    "                            .addBands(thermal_band, None, True)\n",
    "    if sr==False:\n",
    "        #print('sr=False')\n",
    "        imageCloudMasked = imageCloudMasked.addBands(TI, None, True)\n",
    "    \n",
    "    imageCloudMasked = imageCloudMasked.addBands(cloudM)   \n",
    "    \n",
    "    return imageCloudMasked\n",
    "\n",
    "# Composite function\n",
    "def landsat457(roi, date):\n",
    "    collection = filter_col(l4, roi, date).merge(filter_col(l5, roi, date))\n",
    "    image_collection = collection.map(cloud_mask_tm)#.median().clip(roi)\n",
    "    return image_collection\n",
    "\n",
    "def landsat89(roi, date):\n",
    "    collection = filter_col(l8, roi, date).merge(filter_col(l9, roi, date))\n",
    "    image_collection = collection.map(cloud_mask_oli)#.median().clip(roi)\n",
    "    return image_collection\n",
    "\n",
    "def landsat_raw457(roi, date):\n",
    "    collection = filter_col(l4_raw, roi, date).merge(filter_col(l5_raw, roi, date))\n",
    "    image_collection = collection.map(lambda image: cloud_mask_tm(image, sr=False))#.median().clip(roi)\n",
    "    return image_collection\n",
    "    \n",
    "def landsat_raw89(roi, date):\n",
    "    collection = filter_col(l8_raw, roi, date).merge(filter_col(l9_raw, roi, date))\n",
    "    image_collection = collection.map(lambda image: cloud_mask_oli(image, sr=False))#.median().clip(roi)\n",
    "    return image_collection\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9527d09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topographic Correction Function ========================================================================================\n",
    "# Define the function to convert degrees to radians\n",
    "def radians(img):\n",
    "    return img.toFloat().multiply(3.14159265359).divide(180)\n",
    "\n",
    "# Define the function to calculate illumination parameters and angles\n",
    "def calcIlluminationParametersAndAngles(image):\n",
    "    extent = image.geometry().bounds(1)\n",
    "\n",
    "    # Select DEM, calculate aspect and slope\n",
    "    \n",
    "    if type_DEM == 'alos':\n",
    "        DEM = alos\n",
    "    else: \n",
    "        DEM = srtm\n",
    "    \n",
    "    DEM = DEM.clip(extent)\n",
    "    boxcar = ee.Kernel.square(radius=3, units='pixels', normalize=True)\n",
    "    DEMs = DEM.convolve(boxcar)\n",
    "    SLP_deg = ee.Terrain.slope(DEMs)\n",
    "    SLP = radians(SLP_deg)\n",
    "    ASP_deg = ee.Terrain.aspect(DEMs)\n",
    "    ASP = radians(ASP_deg)\n",
    "    cos_SLP = SLP.cos()\n",
    "\n",
    "    if I_satellite == 'LANDSAT':\n",
    "        AZ = ee.Number(image.get('SUN_AZIMUTH'))\n",
    "        ZE = ee.Number(image.get('SUN_ELEVATION'))\n",
    "    elif I_satellite == 'Sentinel':\n",
    "        AZ = ee.Number(image.get('MEAN_SOLAR_AZIMUTH_ANGLE'))\n",
    "        ZE = ee.Number(image.get('MEAN_SOLAR_ZENITH_ANGLE'))\n",
    "\n",
    "    AZ_R = radians(ee.Image(AZ)).clip(extent)\n",
    "    ZE_R = radians(ee.Image(ZE)).clip(extent)\n",
    "    cos_ZE = ZE_R.cos()\n",
    "    cos_ZE_SLP = cos_ZE.multiply(SLP.cos())\n",
    "    cos_VA = ee.Image(0).clip(extent).cos()\n",
    "\n",
    "    # Calculate cos(Z)⋅cos(s) + sin(Z)⋅sin(s)⋅cos(a - a')\n",
    "    IL1 = AZ_R.subtract(ASP).cos().multiply(SLP.sin()).multiply(ZE_R.sin()).add(cos_ZE.multiply(SLP.cos()))\n",
    "    IL2 = IL1.where(IL1.lte(0), 0)\n",
    "    IL3 = IL2.where(IL2.gt(0), 1)\n",
    "    IL = IL1.mask(IL3).select([0], ['IL'])\n",
    "\n",
    "    # Create and return a dictionary\n",
    "    keyList = ee.List(['IL', 'cos_ZE', 'cos_VA', 'cos_SLP', 'SLP', 'ASP'])\n",
    "    valueList = ee.List([IL, cos_ZE, cos_VA, cos_SLP, SLP, ASP])\n",
    "    dictionary = ee.Dictionary.fromLists(keyList, valueList)\n",
    "    return dictionary\n",
    "\n",
    "# Define the function to perform physical correction\n",
    "def doPhysicalCorrection(imageUncorrected, ):\n",
    "    parameters = calcIlluminationParametersAndAngles(imageUncorrected)\n",
    "\n",
    "    cos_ZE = ee.Image(parameters.get('cos_ZE'))\n",
    "    cos_VA = ee.Image(parameters.get('cos_VA'))\n",
    "    cos_SLP = ee.Image(parameters.get('cos_SLP'))\n",
    "\n",
    "    IL = ee.Image(parameters.get('IL'))\n",
    "\n",
    "    imgTC = imageUncorrected.select().addBands(imageUncorrected.select(['blue', 'green', 'red', 'nir', 'swir1', 'swir2'])  \\\n",
    "                                        .mask(imageUncorrected.select(['blue', 'green', 'red', 'nir', 'swir1', 'swir2'])  \\\n",
    "                                        .And(IL).And(imageUncorrected.select('cloudM')))    \\\n",
    "                                        .multiply((((cos_ZE).add(cos_VA))).divide((IL.add(cos_SLP)))))   \\\n",
    "                                        .addBands(imageUncorrected.select('cloudM'))   \\\n",
    "                                        .set('system:time_start', imageUncorrected.get('system:time_start'))\n",
    "\n",
    "    return ee.Image(imgTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1d50fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral Index Formula for FCD\n",
    "# scaling from old formula 8bit to modern images\n",
    "def max_bands(image):\n",
    "    maxRed = image.select('red').reduceRegion(reducer=ee.Reducer.max(),\n",
    "                                                     geometry=AOI,\n",
    "                                                     scale=pca_scale,\n",
    "                                                     bestEffort=True,\n",
    "                                                     tileScale=16)\n",
    "    #print(\"MAXRED\",maxRed)\n",
    "    maxRed = ee.Dictionary(maxRed).toImage()\n",
    "    maxGreen =image.select('green').reduceRegion(reducer=ee.Reducer.max(),\n",
    "                                                 geometry=AOI,\n",
    "                                                 scale=pca_scale,\n",
    "                                                 bestEffort=True,\n",
    "                                                 tileScale=16)\n",
    "    maxGreen = ee.Dictionary(maxGreen).toImage()\n",
    "    maxBlue = image.select('blue').reduceRegion(reducer=ee.Reducer.max(),\n",
    "                                                geometry=AOI,\n",
    "                                                scale=pca_scale,\n",
    "                                                bestEffort=True,\n",
    "                                                tileScale=16)\n",
    "    maxBlue = ee.Dictionary(maxBlue).toImage()\n",
    "    return [maxRed,maxGreen,maxBlue]\n",
    "\n",
    "# Advanced Vegetation index  \n",
    "def AVI_func(image):\n",
    "    AVI = image.expression('((nir + 1 )* (maxRed-red) *(nir -red))**0.333',{\n",
    "        'nir':image.select(['nir']),\n",
    "        'red':image.select(['red']),\n",
    "        'maxRed': max_bands(image)[0],\n",
    "        }\n",
    "    ).rename('AVI') \n",
    "\n",
    "    return AVI\n",
    "\n",
    "# Bare Soil Index \n",
    "# https://www.researchgate.net/publication/319045433_Integration_of_GIS_and_Remote_Sensing_for_Evaluating_Forest_Canopy_Density_Index_in_Thai_Nguyen_Province_Vietnam/link/599293be0f7e9b433f415b40/download\n",
    "\n",
    "def BSI_func(image):\n",
    "    if I_satellite == 'LANDSAT':\n",
    "        BSI = image.expression('(((SWIR1 + red) - (G + NIR)) / ((SWIR1 + red) + (G + NIR)))*100+100',{\n",
    "            'SWIR1':image.select(['swir1']),\n",
    "            'G':image.select(['green']),\n",
    "            'red':image.select(['red']),\n",
    "            'NIR':image.select(['nir']),\n",
    "            }\n",
    "        ).rename('BSI')\n",
    "        \n",
    "    elif I_satellite == 'PlanetNicfi':\n",
    "        BSI = image.expression(\n",
    "            '(NIR + GREEN + RED) / (NIR + GREEN - RED)',  {\n",
    "                  'NIR': image.select('nir'),\n",
    "                  'GREEN': image.select('green'),\n",
    "                  'RED': image.select('red')\n",
    "                    }\n",
    "                ).rename('BSI')\n",
    "  \n",
    "    return BSI\n",
    "\n",
    "def SI_func(image):\n",
    "    SI = image.expression('((maxGreen-Green)*(maxBlue-Blue)*(maxRed-Red))**(1/3)',{  \n",
    "        'Red':image.select(['red']),\n",
    "        'Green':image.select(['green']), #//******\n",
    "        'Blue':image.select(['blue']),\n",
    "        'maxRed': max_bands(image)[0],\n",
    "        'maxGreen': max_bands(image)[1],\n",
    "        'maxBlue': max_bands(image)[2],\n",
    "    }\n",
    "    ).rename('SI')\n",
    "    return SI\n",
    "\n",
    "\n",
    "\n",
    "def normalization_100(image):\n",
    "    #image_scale = ee.Number(image.projection().nominalScale())\n",
    "    image_scale = pca_scale\n",
    "    region = AOI\n",
    "    def normalize_band(name):\n",
    "        name = ee.String(name)\n",
    "        band = image.select(name)\n",
    "        \n",
    "        mean_std = image.reduceRegion(\n",
    "            reducer=ee.Reducer.mean().combine(ee.Reducer.stdDev(), None, True),\n",
    "            geometry=region,\n",
    "            scale=image_scale,\n",
    "            maxPixels=10e9\n",
    "        )\n",
    "        \n",
    "        mean = ee.Number(mean_std.get(name.cat('_mean')))\n",
    "        std = ee.Number(mean_std.get(name.cat('_stdDev')))\n",
    "        \n",
    "        max_value = mean.add(std.multiply(3))\n",
    "        min_value = mean.subtract(std.multiply(3))\n",
    "        \n",
    "        band1 = ee.Image(min_value).multiply(band.lt(min_value)).add(ee.Image(max_value).multiply(band.gt(max_value))) \\\n",
    "            .add(band.multiply(ee.Image(1).subtract(band.lt(min_value)).subtract(band.gt(max_value))))\n",
    "        \n",
    "        result_band = band1.subtract(min_value).divide(max_value.subtract(min_value))\n",
    "        \n",
    "        return result_band\n",
    "    \n",
    "    band_names = image.bandNames()\n",
    "    unit_scale = ee.ImageCollection.fromImages(band_names.map(normalize_band)).toBands().rename(band_names)\n",
    "    return unit_scale.multiply(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af4c666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PRINCIPAL COMPONENT ANALYSIS ########\n",
    "# Define the mean-centered function\n",
    "def means_centered(image, region):\n",
    "    bandNames = image.bandNames()\n",
    "\n",
    "    # Mean center the data\n",
    "    meanDict = image.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=region,\n",
    "        scale=scale,\n",
    "        maxPixels=1e9,\n",
    "        tileScale=12,\n",
    "        bestEffort=True,\n",
    "    )\n",
    "    means = ee.Image.constant(meanDict.values(bandNames))\n",
    "    centered = image.subtract(means)\n",
    "\n",
    "    return [centered, bandNames]\n",
    "\n",
    "# Define the helper function to generate new band names\n",
    "def getNewBandNames(prefix, bandNames):\n",
    "    seq = ee.List.sequence(1, bandNames.length())\n",
    "    return seq.map(lambda b: ee.String(prefix).cat(ee.Number(b).int().format()))\n",
    "\n",
    "# Define the function to get principal components\n",
    "def getPrincipalComponents(centered, scale, region, bandNames):\n",
    "    # Collapse the bands into a 1D array per pixel\n",
    "    arrays = centered.toArray()\n",
    "\n",
    "    # Compute the covariance within the region\n",
    "    covar = arrays.reduceRegion(\n",
    "        reducer=ee.Reducer.centeredCovariance(),\n",
    "        geometry=region,\n",
    "        scale=scale,\n",
    "        maxPixels=1e9,\n",
    "        tileScale=16,\n",
    "        bestEffort=True,\n",
    "        \n",
    "    )\n",
    "\n",
    "    # Get the covariance array result and cast to an array\n",
    "    covarArray = ee.Array(covar.get('array'))\n",
    "\n",
    "    # Perform eigen analysis and slice apart the values and vectors\n",
    "    eigens = covarArray.eigen()\n",
    "\n",
    "    # Extract eigenvalues and eigenvectors\n",
    "    eigenValues = eigens.slice(1, 0, 1)\n",
    "    eigenVectors = eigens.slice(1, 1)\n",
    "\n",
    "    # Convert the array image to 2D arrays\n",
    "    arrayImage = arrays.toArray(1)\n",
    "\n",
    "    # Left multiply the image array by the matrix of eigenvectors\n",
    "    principalComponents = ee.Image(eigenVectors).matrixMultiply(arrayImage)\n",
    "\n",
    "    # Square root of eigenvalues as a P-band image\n",
    "    sdImage = ee.Image(eigenValues.sqrt()) \\\n",
    "        .arrayProject([0]).arrayFlatten([getNewBandNames('sd', bandNames)])\n",
    "\n",
    "    # Normalize the principal components by their standard deviations\n",
    "    return principalComponents \\\n",
    "        .arrayProject([0]) \\\n",
    "        .arrayFlatten([getNewBandNames('pc', bandNames)]) \\\n",
    "        .divide(sdImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e879e842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nlossArea = minLoss.multiply(ee.Image.pixelArea()).divide(10000) #hectare\\nlossSize = lossArea.reduceRegion(\\n    reducer=ee.Reducer.sum(),\\n    geometry=AOI.geometry(),\\n    scale=30,\\n    maxPixels=1e13\\n)\\nprint(\\n    '>Year 2012 tree loss (ha) \\nmeeting minimum canopy cover and \\nforest area thresholds \\n ',\\n    lossSize.get(f'lossfrom_{year_start_loss}'))\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### HISTORICAL DATA THRESHOLD - Get the TCL data LOSS PIXEL overall data from loss year in the input\n",
    "\n",
    "treeLossYear = gfc.select(['lossyear'])\n",
    "treeLoss = treeLossYear.gte(year_start_loss).selfMask() # tree loss in e.g., year > 2012 ####SHOULD CHANGE TO RECENT YEAR for the '12' number\n",
    "#Select the tree loss within the derived tree cover\n",
    "#(>= canopy cover and area requirements). THIS ONE ALREADY MASK TCL IN FOREST AREA\n",
    "treecoverLoss = minArea.And(treeLoss).rename(f'lossfrom_{year_start_loss}').selfMask()\n",
    "\n",
    "#Create connectedPixelCount() to get contiguous area.\n",
    "contLoss = treecoverLoss.connectedPixelCount()\n",
    "#Apply the minimum area requirement, and get the TCL data ---> minLoss - ACTUAL TCL AREA from Hansen since the year_start_loss\n",
    "minLoss = contLoss.gte(lossPixels).selfMask()\n",
    "\n",
    "'''\n",
    "lossArea = minLoss.multiply(ee.Image.pixelArea()).divide(10000) #hectare\n",
    "lossSize = lossArea.reduceRegion(\n",
    "    reducer=ee.Reducer.sum(),\n",
    "    geometry=AOI.geometry(),\n",
    "    scale=30,\n",
    "    maxPixels=1e13\n",
    ")\n",
    "print(\n",
    "    '>Year 2012 tree loss (ha) \\nmeeting minimum canopy cover and \\nforest area thresholds \\n ',\n",
    "    lossSize.get(f'lossfrom_{year_start_loss}'))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6804682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### START SENTINEL CLOUDLESS COMPOSITE AND MOSAICKING\n",
    "\n",
    "#CLOUD_FILTER = 80\n",
    "CLOUD_FILTER = 60\n",
    "CLD_PRB_THRESH = 50\n",
    "NIR_DRK_THRESH = 0.15\n",
    "CLD_PRJ_DIST = 1\n",
    "BUFFER = 50\n",
    "\n",
    "def get_s2_sr_cld_col(aoi, start_date, end_date):\n",
    "    # Import and filter S2 SR.\n",
    "    s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date)\n",
    "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', CLOUD_FILTER)))\n",
    "\n",
    "    # Import and filter s2cloudless.\n",
    "    s2_cloudless_col = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date))\n",
    "\n",
    "    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n",
    "    return ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n",
    "        'primary': s2_sr_col,\n",
    "        'secondary': s2_cloudless_col,\n",
    "        'condition': ee.Filter.equals(**{\n",
    "            'leftField': 'system:index',\n",
    "            'rightField': 'system:index'\n",
    "        })\n",
    "    }))\n",
    "\n",
    "#s2_sr_cld_col_eval = get_s2_sr_cld_col(AOI, START_DATE, END_DATE)\n",
    "\n",
    "def add_cloud_bands(img):\n",
    "    # Get s2cloudless image, subset the probability band.\n",
    "    cld_prb = ee.Image(img.get('s2cloudless')).select('probability')\n",
    "\n",
    "    # Condition s2cloudless by the probability threshold value.\n",
    "    is_cloud = cld_prb.gt(CLD_PRB_THRESH).rename('clouds')\n",
    "\n",
    "    # Add the cloud probability layer and cloud mask as image bands.\n",
    "    return img.addBands(ee.Image([cld_prb, is_cloud]))\n",
    "\n",
    "def add_shadow_bands(img):\n",
    "    # Identify water pixels from the SCL band.\n",
    "    not_water = img.select('SCL').neq(6)\n",
    "\n",
    "    # Identify dark NIR pixels that are not water (potential cloud shadow pixels).\n",
    "    SR_BAND_SCALE = 1e4\n",
    "    dark_pixels = img.select('B8').lt(NIR_DRK_THRESH*SR_BAND_SCALE).multiply(not_water).rename('dark_pixels')\n",
    "\n",
    "    # Determine the direction to project cloud shadow from clouds (assumes UTM projection).\n",
    "    shadow_azimuth = ee.Number(90).subtract(ee.Number(img.get('MEAN_SOLAR_AZIMUTH_ANGLE')));\n",
    "\n",
    "    # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST input.\n",
    "    cld_proj = (img.select('clouds').directionalDistanceTransform(shadow_azimuth, CLD_PRJ_DIST*10)\n",
    "        .reproject(**{'crs': img.select(0).projection(), 'scale': 100})\n",
    "        .select('distance')\n",
    "        .mask()\n",
    "        .rename('cloud_transform'))\n",
    "\n",
    "    # Identify the intersection of dark pixels with cloud shadow projection.\n",
    "    shadows = cld_proj.multiply(dark_pixels).rename('shadows')\n",
    "\n",
    "    # Add dark pixels, cloud projection, and identified shadows as image bands.\n",
    "    return img.addBands(ee.Image([dark_pixels, cld_proj, shadows]))\n",
    "\n",
    "def add_cld_shdw_mask(img):\n",
    "    # Add cloud component bands.\n",
    "    img_cloud = add_cloud_bands(img)\n",
    "\n",
    "    # Add cloud shadow component bands.\n",
    "    img_cloud_shadow = add_shadow_bands(img_cloud)\n",
    "\n",
    "    # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0.\n",
    "    is_cld_shdw = img_cloud_shadow.select('clouds').add(img_cloud_shadow.select('shadows')).gt(0)\n",
    "\n",
    "    # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input.\n",
    "    # 20 m scale is for speed, and assumes clouds don't require 10 m precision.\n",
    "    is_cld_shdw = (is_cld_shdw.focalMin(2).focalMax(BUFFER*2/20)\n",
    "        .reproject(**{'crs': img.select([0]).projection(), 'scale': 30})\n",
    "        .rename('cloudmask'))\n",
    "\n",
    "    # Add the final cloud-shadow mask to the image.\n",
    "    return img_cloud_shadow.addBands(is_cld_shdw)\n",
    "\n",
    "#s2_sr_cld_col_eval_disp = s2_sr_cld_col_eval.map(add_cld_shdw_mask)\n",
    "\n",
    "# Mosaic the image collection\n",
    "#img_mosaic = s2_sr_cld_col_eval_disp.mosaic()\n",
    "\n",
    "def apply_cld_shdw_mask(img):\n",
    "    # Subset the cloudmask band and invert it so clouds/shadow are 0, else 1.\n",
    "    not_cld_shdw = img.select('cloudmask').Not()\n",
    "\n",
    "    # Subset reflectance bands and update their masks, return the result.\n",
    "    return img.select('B.*').updateMask(not_cld_shdw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14f6a1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndwi_landsat threshold 0.1\n"
     ]
    }
   ],
   "source": [
    "# DECISION RUNNING SENTINEL AND NDWI RELATED\n",
    "if I_satellite == 'Sentinel':\n",
    "    ndwi_hi = ndwi_hi_sentinel # for Sentinel\n",
    "\n",
    "    s2_sr_cld_col = get_s2_sr_cld_col(AOI, START_DATE, END_DATE)\n",
    "\n",
    "    SEN_BANDS = ['B2',   'B3', 'B4',  'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12']\n",
    "    bandNamesSentinel2 = ['blue', 'green', 'red', 'redE1', 'redE2', 'redE3', 'nir', 'redE4', 'swir1', 'swir2']\n",
    "\n",
    "    s2_sr_median = (s2_sr_cld_col.map(add_cld_shdw_mask)\n",
    "                                 .map(apply_cld_shdw_mask)\n",
    "                                 .select(SEN_BANDS, bandNamesSentinel2)\n",
    "                                 .median())\n",
    "    # VISUALIZE SENTINEL CLOUDLESS\n",
    "    Map.addLayer(s2_sr_median.clip(AOI),\n",
    "                    {'bands': ['swir2', 'nir', 'red'], 'min': 0, 'max': 6000, 'gamma': 1.1},\n",
    "                    'S2 cloud-free mosaic')\n",
    "\n",
    "    Map.addLayer(treeLossYear.clip(AOI),{\"opacity\":1,\"bands\":[\"lossyear\"],\"min\":1,\"max\":21,\"palette\":[\"3d358c\",\"4457c9\",\"4777f0\",\"4196ff\",\"2eb4f3\",\"1ad1d5\",\"1ae5b6\",\"36f493\",\"64fd6a\",\"92ff47\",\"b4f836\",\"d3e935\",\"ecd239\",\"fbb938\",\"fe992c\",\"f9751d\",\"ec520e\",\"d93806\",\"bf2102\",\"9f1001\",\"7a0403\"]},\"Tree Loss Year\",False)\n",
    "    Map.addLayer(minLoss.clip(AOI),{\n",
    "        'palette': ['#ff0000']\n",
    "    }, f'tree cover >30% loss since 20{year_start_loss}',False)\n",
    "elif I_satellite == 'LANDSAT':\n",
    "    ndwi_hi = ndwi_hi_landsat # for Landsat\n",
    "    print('ndwi_landsat threshold',ndwi_hi )\n",
    "    \n",
    "else:\n",
    "    ndwi_hi = ndwi_hi_planet\n",
    "    print('ndwi_planet threshold',ndwi_hi )\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c3c6574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to use Sentinel data for generating Forest, from NDVI, BI, SI\n",
    "def applying_sentinel_forest(s2_sr_median,ndvi_hi,bi_hi,si_hi,pixels): \n",
    "    ############# SPECTRAL INDICES #############################\n",
    "    #NDVI - NORMALIZED DIFFERENCES VEGETATION INDEX\n",
    "    ndvi = s2_sr_median.normalizedDifference(['nir','red'])\n",
    "    #BARELAND/ BARE SOIL INDEX\n",
    "    bi_1 = s2_sr_median.expression(\n",
    "        '(NIR + GREEN + RED) / (NIR + GREEN - RED)', \n",
    "            {\n",
    "          'NIR': s2_sr_median.select('nir').divide(10000),\n",
    "          'GREEN': s2_sr_median.select('green').divide(10000),\n",
    "          'RED': s2_sr_median.select('red').divide(10000)\n",
    "            })\n",
    "    #SOIL INDEX\n",
    "    si = s2_sr_median.expression(\n",
    "         '((1 - GREEN) * (1 - RED) )**(0.5)' ,\n",
    "        {\n",
    "          'GREEN': s2_sr_median.select('green').divide(10000),\n",
    "          'RED': s2_sr_median.select('red').divide(10000)\n",
    "        })\n",
    "\n",
    "    #Map.addLayer(ndvi,{},'NDVI')\n",
    "    #Map.addLayer(bi_1,{},'BI_1')\n",
    "    #Map.addLayer(si,{},'SI')\n",
    "    ############################################################\n",
    "\n",
    "    ########### DECISION ON THE DEFINITION\n",
    "    # NDVI > NDVI_High threshold\n",
    "    ndviHi_masked = ndvi.updateMask(ndvi.gt(ndvi_hi))\n",
    "    # BI < BI_High threshold\n",
    "    bi_1Lo_masked = bi_1.updateMask(bi_1.lt(bi_hi))\n",
    "    # Shadow Index (SI)> SI threshold\n",
    "    siHi_masked = si.updateMask(si.gt(si_hi))\n",
    "\n",
    "    #### HIGH DENSITY FOREST DECISION\n",
    "    # If ndvi is high enough, baresoil index is low and shadow index is high, then it is a high density forest based on this\n",
    "    hiforest_masked = ndviHi_masked.And(bi_1Lo_masked).And(siHi_masked)\n",
    "    #Create connectedPixelCount() to get contiguous area, minimum mapping unit\n",
    "    conthiForest = hiforest_masked.connectedPixelCount()\n",
    "    #Apply the minimum area requirement, for the final result one area should have at least \n",
    "    hiforest_masked = conthiForest.gte(pixels).selfMask()\n",
    "    \n",
    "    #Map.addLayer(hiforest_masked.clip(AOI),{'palette':hi_forest},'High Forest',False)\n",
    "\n",
    "    '''\n",
    "    #Low density Forest - not used anywhere\n",
    "    ndviMid_masked = ndvi.updateMask(ndvi.lt(ndvi_hi).And(ndvi.gt(ndvi_lo)))\n",
    "    siMid_masked = si.updateMask(si.lt(si_hi).And(si.gt(si_lo)))\n",
    "\n",
    "    loforest_masked = ndviMid_masked.And(bi_1Lo_masked).And(siMid_masked)\n",
    "    #Map.addLayer(loforest_masked,{'palette':low_forest},'Low Forest')\n",
    "    '''\n",
    "    return hiforest_masked.clip(AOI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82b0ec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "def assigning_band(band_name_image,class_value,srcImg):\n",
    "        \n",
    "    # Create an image with the constant value for class\n",
    "    constant_image_class = srcImg.multiply(0).add(class_value).rename(band_name_image)\n",
    "    constant_image_pixel = srcImg.multiply(0).add(1).rename('pixel')\n",
    "    \n",
    "    # Add the new band to the existing image\n",
    "    pixel_bandimg= srcImg.addBands(constant_image_pixel)\n",
    "    pix_classImg = pixel_bandimg.addBands(constant_image_class)\n",
    "    pix_classImg = pix_classImg.select([band_name_image,'pixel'])\n",
    "    \n",
    "    return pix_classImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cbeb349",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VERSION 1 for Sentinel as forest basemap, and followed by Hansen data - in function ####################################\n",
    "def applying_sentinel_water(s2_sr_median, ndwi_hi):\n",
    "\n",
    "    # Normalized Differences Water Index\n",
    "    ndwi = s2_sr_median.normalizedDifference(['green','nir'])\n",
    "    #Map.addLayer(ndwi,{},'NDWI')\n",
    "\n",
    "    # Mask the non-watery parts of the image, where NDWI < ndwi_hi.\n",
    "    waterMasked = ndwi.updateMask(ndwi.gt(ndwi_hi))\n",
    "    #Map.addLayer(waterMasked, {'palette': water}, 'NDWI (Water) masked')\n",
    "    \n",
    "    ##### Get the area only that is not possible for planting (Water)\n",
    "    waterinAOI = waterMasked.And(AOI_img)\n",
    "    #Map.addLayer(waterinAOI,{'palette': water},\"Water in AOI\")\n",
    "    water_edited = ee.Image(assigning_band(band_name_image,5,waterinAOI))\n",
    "    return [waterinAOI,water_edited]\n",
    "\n",
    "def applying_zone_sentinel_hansen(hiforest_masked,minLoss,s2_sr_median, ndwi_hi):\n",
    "    \n",
    "    ######### Zone 2 - High Baseline Forest: That does not have (overlaid with) TCL \n",
    "    # Unmasked the forest loss 10 years rule\n",
    "    unmaskedLoss = AOI_img.unmask().updateMask(minLoss.mask().Not()).clip(AOI)\n",
    "    highBaselineF = hiforest_masked.And(unmaskedLoss)\n",
    "    #Map.addLayer(highBaselineF,{'palette':hi_forest},'High baseline (Forest)')\n",
    "    \n",
    "    # assigning class band 2\n",
    "    highf_edited = ee.Image(assigning_band(band_name_image,2,highBaselineF)) #high baseline forest - 2\n",
    "    ##################################################\n",
    "    \n",
    "    ######### Zone 3: High Forest and Loss (e.g., Young Regenerating Forest)\n",
    "    ####### Get the overlay information of HighBaseline (Sentinel) and Tree Cover Loss (Hansen), e.g., Young Regenerating Forest\n",
    "    HiForestAndLoss = AOI_img.And(hiforest_masked.And(minLoss)) #minLoss is the actual TCL without overlaying with Sentinel\n",
    "    #Map.addLayer(HiForestAndLoss,{'palette': '#FF0000'},\"High Baseline and not pass 10 years rule\")\n",
    "    \n",
    "    # Final Result for High Forest and TCL -> Class number: 3\n",
    "    tenyrfl_edited = ee.Image(assigning_band(band_name_image,3,HiForestAndLoss)) #tenyears rule not pass and high baseline - 3\n",
    "    ##############################################\n",
    "    \n",
    "    ######### Zone 4: Tree Cover Loss on the current low baseline (Sentinel)\n",
    "    ###### Get the 10 years data only that is not overlay with Sentinel High baseline (Forest) #############\n",
    "    # Create a helper mask indicating where the smaller areas maskhiFL, distinguish only the highbaseline and TCL (mask) and assign mask as 1\n",
    "    maskHiFL = HiForestAndLoss.mask()\n",
    "    #Map.addLayer(maskHiFL)\n",
    "    # Helper - Invert the mask to get the areas where the smaller raster is absent - get only area outside high forest and loss, and mask from 1 to 0\n",
    "    # invert mask just to get the number from 0 to 1 or vice versa -> .Not()\n",
    "    maskHiFL_inverted = maskHiFL.Not()\n",
    "    #Map.addLayer(maskHiFL_inverted)\n",
    "    # Unmask the bigger raster in the areas to get the pixel value for area 'outside' HiFL (High Baseline and Forest Loss)\n",
    "    unmaskedHiFL = AOI_img.unmask().updateMask(maskHiFL_inverted).clip(AOI)\n",
    "    #Map.addLayer(unmaskedHiFL)\n",
    "    #outcome result for 10 years data only that is not overlay with Sentinel High baseline (Forest) unmaskedHiFL is Area that is not Forest Sentinel############\n",
    "    tenYearsRule = unmaskedHiFL.And(minLoss)\n",
    "    #Map.addLayer(tenYearsRule,{'palette': '#FFA500'},\"10 Years Rule - not OK\")\n",
    "    \n",
    "    # assign the Class into no. 4 - Final Result\n",
    "    tenyrule_edited = ee.Image(assigning_band(band_name_image,4,tenYearsRule)) #tenyears rule not pass - 4\n",
    "    ###############################################\n",
    "    \n",
    "    ######### Zone 5: Water Body - NDWI Sentinel\n",
    "    # from a function, output is already assigned in a band name: Class : 5\n",
    "    #water_list = applying_sentinel_water(s2_sr_median, ndwi_hi)\n",
    "    #waterinAOI = water_list[0]\n",
    "    #water_edited = water_list[1]\n",
    "    \n",
    "    # Use hansen data instead - better result, no need to adjust threshold and water body not change for long time\n",
    "    WaterMask = gfc.select(['datamask']).rename('datamask').eq(2)\n",
    "    waterinAOI = AOI_img.mask().updateMask(WaterMask)\n",
    "    water_edited = ee.Image(assigning_band(band_name_image,5,waterinAOI)).clip(AOI)\n",
    "    # unmasked the water (hansen)\n",
    "    unmaskedWaterAOI = AOI_img.unmask().updateMask(waterinAOI.mask().Not()).clip(AOI)\n",
    "    \n",
    "    ###############################################\n",
    "\n",
    "\n",
    "    ######### Zone 1: Go Zone - outside (forest, forest - TCL, no-forest TCL, WaterBody)\n",
    "    # Utils - Similar with above (but easier), unmasked the high forest means that in the end only include area that is not in forest (hiforest_masked)\n",
    "    maskHiF = hiforest_masked.mask()\n",
    "    maskHiF_inverted = maskHiF.Not()\n",
    "    # Unmasked High Forest - the result is all the area outside of hiforest_masked (Total all forest), and now in no forest\n",
    "    unmaskedHiF = AOI_img.unmask().updateMask(maskHiF_inverted).clip(AOI)\n",
    "    # unmasked the water\n",
    "    #unmaskedWaterAOI = AOI_img.unmask().updateMask(waterinAOI.mask().Not()).clip(AOI)\n",
    "    \n",
    "    goZone = unmaskedLoss.And(unmaskedHiF).And(unmaskedWaterAOI)\n",
    "    #Map.addLayer(goZone,{'palette':'#FFFF00'},'Go Zone')\n",
    "    # assigning band - Go Zone\n",
    "    goZone_edited = ee.Image(assigning_band(band_name_image,1,goZone)) #go Zone - 1\n",
    "    ##############################################\n",
    "    \n",
    "    Map.addLayer(goZone_edited,{'bands': ['Class'],'palette':'#FFFF00'},'Go Zone')\n",
    "    Map.addLayer(highf_edited,{'bands': ['Class'],'palette':hi_forest},'High baseline (Forest)')\n",
    "    Map.addLayer(tenyrfl_edited,{'bands': ['Class'],'palette': '#FF0000'},\"High Baseline and not pass 10 years rule\")\n",
    "    Map.addLayer(tenyrule_edited,{'bands': ['Class'],'palette': '#FFA500'},\"10 Years Rule - not OK\")\n",
    "    Map.addLayer(water_edited,{'bands': ['Class'],'palette': water},\"Water in AOI\")\n",
    "    \n",
    "    labels = ['High Baseline (Forest)', '10 Years Rule not OK', 'High Baseline not passed 10 years rule', 'Water', 'Go Zone']\n",
    "    # colorS can be defined using either hex code or RGB (0-255, 0-255, 0-255)\n",
    "    colors = ['#006837', '#FFA500', '#FF0000', '#3380cc', '#FFFF00']\n",
    "    # legend_colors = [(255, 0, 0), (127, 255, 0), (127, 18, 25), (36, 70, 180), (96, 68 123)]\n",
    "\n",
    "    Map.add_legend(title='Legend', labels=labels, colors=colors)\n",
    "\n",
    "    ''' mosaicking into single image  - still does not work\n",
    "    #image_list = ee.List([goZone_edited, highf_edited, tenyrfl_edited, tenyrule_edited, water_edited ])\n",
    "    # Extract the spatial information from one of the individual images.\n",
    "    projection = goZone_edited.projection()\n",
    "    scale = goZone_edited.projection().nominalScale()\n",
    "\n",
    "    # Create an ee.ImageCollection from the list of images\n",
    "    image_collection = ee.ImageCollection([goZone_edited, highf_edited, tenyrfl_edited, tenyrule_edited, water_edited ])\n",
    "\n",
    "    # Merge the images into a single ee.Image\n",
    "    zoning_final = image_collection.mosaic()\n",
    "    '''\n",
    "    return [goZone_edited,highf_edited,tenyrfl_edited,tenyrule_edited, water_edited]\n",
    "\n",
    "def apply_arief_equation(s2_sr_median, threshold):\n",
    "    # equation selected: Y = e**(43.2 - 380 X1 – 0.00970 X2 + 0.916 X3 + 6.5 X4- 30.6 X5 + 259 X6)\n",
    "    # equation2 selected: Y = 6196 - 64212 X1 - 1.29 X2 + 120.0 X3 + 954 X4- 4547 X5 + 43814 X6\n",
    "    # X1 = NDVI = (NIR - RED)/ (NIR + RED)\n",
    "    # X2 = DVI = NIR – Red\n",
    "    # X3 = RDVI = (NIR - Red)/((NIR + RED)**0.5)  \n",
    "    # X4 = SR = NIR/Red \n",
    "    # X5 = MSRVI = ((NIR/Red) - 1)/((NIR/Red)**0.5 - 1)\n",
    "    # X6 = SAVI = ((NIR - RED)/(NIR + RED + 0.5))*1.5\n",
    "\n",
    "    #NDVI - NORMALIZED DIFFERENCES VEGETATION INDEX\n",
    "    ndvi = s2_sr_median.normalizedDifference(['nir','red']).rename('ndvi')\n",
    "    \n",
    "    # DVI\n",
    "    dvi = s2_sr_median.expression(\n",
    "        '(NIR - RED)', \n",
    "            {\n",
    "          'NIR': s2_sr_median.select('nir'),#.divide(10000),\n",
    "          'RED': s2_sr_median.select('red'),#.divide(10000)\n",
    "            }).rename('dvi')\n",
    "\n",
    "    \n",
    "    # RDVI\n",
    "    rdvi = s2_sr_median.expression(\n",
    "        '(NIR - Red)/((NIR + Red)**0.5)',\n",
    "            {\n",
    "            'NIR': s2_sr_median.select('nir'),#.divide(10000),\n",
    "            'Red': s2_sr_median.select('red'),#.divide(10000)\n",
    "            }\n",
    "        ).rename('rdvi')\n",
    "    \n",
    "    # SR - Simple Ratio\n",
    "    sr_index = s2_sr_median.expression(\n",
    "        'NIR/Red',\n",
    "            {\n",
    "            'NIR': s2_sr_median.select('nir'),#.divide(10000),\n",
    "            'Red': s2_sr_median.select('red'),#.divide(10000)\n",
    "            }\n",
    "        ).rename('sr_index')\n",
    "    \n",
    "    # MSRVI\n",
    "    msrvi = s2_sr_median.expression(\n",
    "        '((NIR/Red) - 1)/((NIR/Red)**0.5 - 1)',\n",
    "            {\n",
    "            'NIR': s2_sr_median.select('nir'),#.divide(10000),\n",
    "            'Red': s2_sr_median.select('red'),#.divide(10000)\n",
    "            }\n",
    "        ).rename('msrvi')\n",
    "    \n",
    "    # SAVI\n",
    "    savi = s2_sr_median.expression(\n",
    "        '((NIR - RED)/(NIR + RED + 0.5))*1.5',\n",
    "            {\n",
    "            'NIR': s2_sr_median.select('nir'),#.divide(10000),\n",
    "            'RED': s2_sr_median.select('red'),#.divide(10000)\n",
    "            }\n",
    "        ).rename('savi')\n",
    "    \n",
    "    all_spec_index = ndvi.addBands(ee.Image(dvi)) \\\n",
    "                                 .addBands(ee.Image(sr_index)) \\\n",
    "                                 .addBands(ee.Image(msrvi)) \\\n",
    "                                 .addBands(ee.Image(rdvi)) \\\n",
    "                                 .addBands(ee.Image(savi))\n",
    "                        \n",
    "    e_num = math.e\n",
    "    # print(e_num)\n",
    "    # from arief et al, https://journal.itera.ac.id/index.php/jsat/article/view/964/348\n",
    "    arief_etal = all_spec_index.expression(\n",
    "            'e**(43.2 - (380* X1) - (0.00970* X2) + (0.916* X3) + (6.5* X4) - (30.6* X5) + (259* X6))',\n",
    "            #'6196 - (64212 * X1) - (1.29 * X2) + (120.0 * X3) + (954 * X4)- (4547 * X5) + (43814 * X6)',\n",
    "            {\n",
    "                'e': e_num,\n",
    "                'X1': all_spec_index.select('ndvi'),\n",
    "                'X2': all_spec_index.select('dvi'),\n",
    "                'X3': all_spec_index.select('rdvi'),\n",
    "                'X4': all_spec_index.select('sr_index'),\n",
    "                'X5': all_spec_index.select('msrvi'),\n",
    "                'X6': all_spec_index.select('savi'),\n",
    "            }\n",
    "        ).rename('y_regression')\n",
    "    #Map.addLayer(all_spec_index.clip(AOI),{},'INDEXXXX_ALL')\n",
    "    #Map.addLayer(arief_etal.clip(AOI),{},'y')\n",
    "    spec_forest = arief_etal.gte(threshold).selfMask()\n",
    "    #Map.addLayer(spec_forest.clip(AOI),{},'y_forest')\n",
    "    return spec_forest\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a6f9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(band_names_ref, band_name_image,high_forest_image ):\n",
    "    \n",
    "    ref_values = gdf_ref[band_names_ref].values\n",
    "    print(\"Reference_values: \", ref_values)\n",
    "    # Select the band of interest from the image to know what classified 1 Forest (High baseline), 0 (outside)\n",
    "    #band_name_image = 'Class'\n",
    "    band = high_forest_image.select([band_name_image])\n",
    "    \n",
    "    # Unmask the band, replacing masked values (null) - Class: null with 0\n",
    "    unmasked_band = band.unmask(0)\n",
    "    \n",
    "    # Use sampleRegions to extract pixel values at the point locations\n",
    "    sampled_points = unmasked_band.sampleRegions(\n",
    "        collection=ref_point_loc,\n",
    "        scale=10\n",
    "    )\n",
    "\n",
    "    # Get the pixel values as a list - another way to get the ref_values\n",
    "    # ref_values = sampled_points.aggregate_array('Forest_Sen').getInfo()\n",
    "\n",
    "    # Get the pixel values as a list\n",
    "    pixel_values = sampled_points.aggregate_array(band_name_image).getInfo()\n",
    "\n",
    "    # Print the pixel values\n",
    "    print(\"Pixel Values: \", pixel_values)\n",
    "    \n",
    "    confusion_mat = confusion_matrix(ref_values, pixel_values)\n",
    "    print(\"Confusion matrix summary: \\n\", confusion_mat)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(ref_values, pixel_values).ravel()\n",
    "    \n",
    "    print(\"TN:\",tn,\"\\n FP:\",fp, \"\\n FN:\",fn, \"\\n TP:\",tp)\n",
    "    \n",
    "    accuracy = ((tp + tn) / (tp + tn + fp + fn))*100.00\n",
    "    print(\"Accuracy: (%) \",accuracy)\n",
    "    \n",
    "    precision = (tp / (tp + fp))*100.00\n",
    "    print(\"Precision: (%) \",precision)\n",
    "    \n",
    "    prod_acc = (tp / (tp + fn))*100.00\n",
    "    print(\"Producer Accuracy: (%) \",prod_acc) #means that how is the raster result (image) predict forest only,\n",
    "    \n",
    "    user_acc = (tn / (tn + fp))*100.00\n",
    "    print(\"User Accuracy: (%) \",user_acc)\n",
    "    return [tn, fp, fn, tp]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddf30a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' What confusion matrix look like\\n                 Predicted Class\\n               | Forest (1) | No Forest (0) |\\nTrue Class     |------------|--------------|\\nForest (1)     |    TP      |      FN      |\\nNo Forest (0)  |    FP      |      TN      |\\n\\nHere is the definition of accuracy and precision\\n\\nAccuracy: The overall accuracy of the classification.\\n\\nAccuracy = (TP + TN) / (TP + TN + FP + FN)\\n\\nPrecision: The proportion of correctly classified positive samples (class 1) out of all samples classified as positive.\\n\\nPrecision = TP / (TP + FP)\\n\\nProducer Accuracy (also known as Recall or Sensitivity): The proportion of correctly classified positive samples (class 1) out of all actual positive samples.\\n\\nProducer Accuracy = TP / (TP + FN)\\n\\nUser Accuracy (also known as Specificity): The proportion of correctly classified negative samples (class 0) out of all actual negative samples.\\n\\nUser Accuracy = TN / (TN + FP)\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' What confusion matrix look like\n",
    "                 Predicted Class\n",
    "               | Forest (1) | No Forest (0) |\n",
    "True Class     |------------|--------------|\n",
    "Forest (1)     |    TP      |      FN      |\n",
    "No Forest (0)  |    FP      |      TN      |\n",
    "\n",
    "Here is the definition of accuracy and precision\n",
    "\n",
    "Accuracy: The overall accuracy of the classification.\n",
    "\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "Precision: The proportion of correctly classified positive samples (class 1) out of all samples classified as positive.\n",
    "\n",
    "Precision = TP / (TP + FP)\n",
    "\n",
    "Producer Accuracy (also known as Recall or Sensitivity): The proportion of correctly classified positive samples (class 1) out of all actual positive samples.\n",
    "\n",
    "Producer Accuracy = TP / (TP + FN)\n",
    "\n",
    "User Accuracy (also known as Specificity): The proportion of correctly classified negative samples (class 0) out of all actual negative samples.\n",
    "\n",
    "User Accuracy = TN / (TN + FP)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7cd3fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDING VISUAL FOR CHECKING AND VERIFY THE RESULT\n",
    "visPlanet_veg = {\"bands\":[\"red\",\"nir\",\"blue\"],\"min\":0,\"max\":0.6,\"gamma\":1.5}\n",
    "truePlanet_veg = {\"bands\":[\"red\",\"green\",\"blue\"],\"min\":0,\"max\":0.6,\"gamma\":1.5}\n",
    "\n",
    "Map.addLayer(filtered_scaled, visPlanet_veg , 'NICFI Cloudless Image - RNB')\n",
    "Map.addLayer(filtered_scaled, truePlanet_veg , 'NICFI Cloudless Image - RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b895c9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting LANDSAT images\n",
      "processing AVI\n",
      "processing BSI\n",
      "processing SI\n",
      "Normalizing to 100 AVI\n",
      "Normalizing to 100 BSI\n",
      "Normalizing to 100 SI\n",
      "Combining AVI AND BSI\n",
      "Processing means center of AVI_BSI please wait\n",
      "Now we get to the PCA of Vegetation density\n",
      "Success get the PCA normalized of VD => SVI\n",
      "Processing means center of SI and TI please wait\n",
      "Now we get to the PCA of SI and TI\n",
      "Success get the PCA normalized of SI and TI => SSI\n",
      "Now calculating the FCD from SVI and SSI - selecting band svi1 svi2 ssi1 and ssi2\n",
      "Now calculating the FCD from SVI2 and SSI1 into FCD in percentage\n",
      "finish processing PCA please continue\n"
     ]
    }
   ],
   "source": [
    "if algor_process == 'fcd_galcit':\n",
    "    if I_satellite == 'LANDSAT':\n",
    "        print('selecting LANDSAT images')\n",
    "        date = [START_DATE, END_DATE]\n",
    "        date_object = datetime.strptime(END_DATE, \"%Y-%m-%d\")\n",
    "        year = date_object.year\n",
    "\n",
    "        if year < 2014:\n",
    "            landsat = landsat457\n",
    "            landsat_raw = landsat_raw457\n",
    "        else:\n",
    "            landsat = landsat89\n",
    "            landsat_raw = landsat_raw89\n",
    "        image_col = landsat(AOI, date)\n",
    "        image_uncorrected = landsat(AOI, date).median().clip(AOI)\n",
    "        image_corrected = image_col.map(doPhysicalCorrection).median().clip(AOI)\n",
    "        Map.addLayer(image_uncorrected,{'bands': ['swir2', 'nir', 'red'], 'min': 0, 'max': 0.6, 'gamma': 1.5 }, f'landsat_for_FCD_{year}_uncorrected')\n",
    "        Map.addLayer(image_corrected,{'bands': ['swir2', 'nir', 'red'], 'min': 0, 'max': 0.6, 'gamma': 1.5 }, f'landsat_for_FCD_{year}_corrected')\n",
    "    \n",
    "    elif I_satellite == 'PlanetNicfi':\n",
    "        print('selecting Planet NICFI images')\n",
    "        image_corrected = filtered_scaled\n",
    "        \n",
    "    print('processing AVI')\n",
    "    avi_image = AVI_func(image_corrected)\n",
    "    #Map.addLayer(avi_image,{},'avi')\n",
    "    \n",
    "    print('processing BSI')\n",
    "    bsi_image = BSI_func(image_corrected)\n",
    "    #Map.addLayer(bsi_image,{},'bsi')\n",
    "    \n",
    "    print('processing SI')\n",
    "    si_image = SI_func(image_corrected)\n",
    "    #Map.addLayer(si_image,{},'si_no_norm')\n",
    "        \n",
    "    #Map.addLayer(image_corr_8,{'bands': ['swir2', 'nir', 'red'], 'min': 0, 'max': 256,  }, f'landsat_for_FCD_{year}_corrected_8bit')        \n",
    "    print('Normalizing to 100 AVI')\n",
    "    # Starting (normalized 100) Indices\n",
    "    avi_norm = normalization_100(avi_image)\n",
    "    Map.addLayer(avi_norm,{'min':0,'max':100},'avi_norm')\n",
    "    print('Normalizing to 100 BSI')\n",
    "    bsi_norm = normalization_100(bsi_image)\n",
    "    Map.addLayer(bsi_norm,{'min':0,'max':100},'bsi_norm')\n",
    "    print('Normalizing to 100 SI')\n",
    "    si_norm = normalization_100(si_image)\n",
    "    Map.addLayer(si_norm, {'min':0,'max':100},'si_norm')\n",
    "    print('Combining AVI AND BSI')\n",
    "    # Combine  AVI and BSI to one image with two bands \n",
    "    AVI_BSI = avi_norm.addBands(bsi_norm)\n",
    "    # Masked-out process or remove null data, to avoid errors\n",
    "    avi_bsi_clean = AVI_BSI.gte(0).Or(AVI_BSI.lte(0))\n",
    "    AVI_BSI = AVI_BSI.updateMask(avi_bsi_clean)\n",
    "    #Map.addLayer(AVI_BSI, {'min':0,'max':100}, 'AVI_BSI')\n",
    "    \n",
    "    print('Processing means center of AVI_BSI please wait')\n",
    "    # Means Centered for VD --- VD WILL GIVE YOU ERROR ---> if you dont masked out first\n",
    "    Means_cn = means_centered(AVI_BSI, AOI)\n",
    "    #print('Means_cn[0]',Means_cn[0])\n",
    "    #print('Means_cn[1]',Means_cn[1])\n",
    "    \n",
    "    print('Now we get to the PCA of Vegetation density')\n",
    "    # PCA FOR AVI AND BSI = VD and SVI\n",
    "    VD = getPrincipalComponents(Means_cn[0], pca_scale, AOI, Means_cn[1]).rename(['VD1', 'VD2'])\n",
    "    #Map.addLayer(VD,{},'VD')\n",
    "    # scale VD datasets \n",
    "    SVI = normalization_100(VD)\n",
    "    Map.addLayer(SVI,{'min':0,'max':100},'SVI')\n",
    "    print('Success get the PCA normalized of VD => SVI')\n",
    "    \n",
    "    \n",
    "    if TI_include: \n",
    "        #image_raw = landsat_raw(AOI, date).median().clip(AOI)\n",
    "        image_col_raw = landsat_raw(AOI, date)\n",
    "\n",
    "        # Define the weighted median function\n",
    "        def weighted_median(collection):\n",
    "            # Sort the collection by the timestamp in descending order\n",
    "            sorted_collection = collection.sort('system:time_start', False)\n",
    "\n",
    "            # Compute the weighted median\n",
    "            weighted_median = sorted_collection.median()\n",
    "\n",
    "            return weighted_median\n",
    "\n",
    "        # Compute the weighted median\n",
    "        image_raw = weighted_median(image_col_raw).clip(AOI)\n",
    "        #image_raw = image_col_raw.median().clip(AOI)\n",
    "\n",
    "        #Map.addLayer(image_raw, {'bands': ['swir2', 'nir', 'red'], 'min': 0, 'max': 20000, 'gamma': 1.5 },'image_raw')\n",
    "\n",
    "        ti_norm = normalization_100(image_raw.select('TI'))\n",
    "        Map.addLayer(ti_norm,{'min':0,'max':100},'TI_norm')\n",
    "        #Map.addLayer(image_raw,{'bands': ['swir2', 'nir', 'red'], 'min': 0, 'max': 6, 'gamma': 1.5 },'ti_image')\n",
    "\n",
    "        # Combine SI and TI to one image with two bands\n",
    "        SI_TI = si_norm.addBands(ti_norm)\n",
    "        #Map.addLayer(SI_TI, {'min':0,'max':100}, 'SI_TI')\n",
    "\n",
    "        print('Processing means center of SI and TI please wait')\n",
    "        # Means centered FOR SI AND TI (NORMALIZED)\n",
    "        # Means Centered for SSI --- SSI WILL GIVE YOU ERROR ---> if you dont masked out first\n",
    "        Means_cn_siti = means_centered(SI_TI, AOI) \n",
    "        #print('Means_cn_siti[0]',Means_cn_siti[0])\n",
    "        #print('Means_cn_siti[1]',Means_cn_siti[1])\n",
    "\n",
    "        print('Now we get to the PCA of SI and TI')\n",
    "        # PCA FOR AVI AND BSI = VD and SVI\n",
    "        SI_TI_PCA = getPrincipalComponents(Means_cn_siti[0], pca_scale, AOI, Means_cn_siti[1]).rename(['SSI1', 'SSI2'])\n",
    "        SSI = normalization_100(SI_TI_PCA)\n",
    "        #Map.addLayer(SI_TI_PCA,{}, 'SI_TI_PCA')\n",
    "        Map.addLayer(SSI,{'min':0,'max':100},'SSI')\n",
    "        print('Success get the PCA normalized of SI and TI => SSI')\n",
    "        \n",
    "        print('Now calculating the FCD from SVI and SSI - selecting band svi1 svi2 ssi1 and ssi2')\n",
    "        svi1 = SVI.select(['VD1'])\n",
    "        ssi1 = SSI.select(['SSI1'])\n",
    "\n",
    "        # Starting to include in the formula for Forest Cover Density\n",
    "        FCD1_1 = (((svi1.multiply(ssi1)).add(1)).pow(0.5)).subtract(1)\n",
    "        Map.addLayer(FCD1_1, {'min':0 ,'max':80, 'palette':['ff4c16', 'ffd96c', '39a71d']}, 'FCD1_1')\n",
    "        #Map.addLayer(FCD1.mask(FCD1.gte(30)), {'min':0 ,'max':80, 'palette':['ff4c16', 'ffd96c', '39a71d']}, 'FCD1_morethan30')\n",
    "\n",
    "        svi2 = SVI.select(['VD2'])\n",
    "        ssi2 = SSI.select(['SSI2'])\n",
    "\n",
    "        FCD2_2 = (((svi2.multiply(ssi2)).add(1)).pow(0.5)).subtract(1)\n",
    "\n",
    "        Map.addLayer(FCD2_2, {'min':0 ,'max':80, 'palette':['ff4c16', 'ffd96c', '39a71d']}, 'FCD2_2')\n",
    "        #Map.addLayer(FCD2_2.mask(FCD2_2.gte(30)), {'min':0 ,'max':80, 'palette':['ff4c16', 'ffd96c', '39a71d']}, 'FCD2_2_morethan30')\n",
    "\n",
    "        FCD1_2 = (((svi1.multiply(ssi2)).add(1)).pow(0.5)).subtract(1)\n",
    "\n",
    "        Map.addLayer(FCD1_2, {'min':0 ,'max':80, 'palette':['ff4c16', 'ffd96c', '39a71d']}, 'FCD1_2')\n",
    "        #Map.addLayer(FCD1_2.mask(FCD1_2.gte(30)), {'min':0 ,'max':80, 'palette':['ff4c16', 'ffd96c', '39a71d']}, 'FCD1_2_morethan30')\n",
    "\n",
    "        print('Now calculating the FCD from SVI2 and SSI1 into FCD in percentage')\n",
    "        # The best on AOI_B30 based on the visual check, combination svi2 and ssi1\n",
    "        FCD2_1 = (((svi2.multiply(ssi1)).add(1)).pow(0.5)).subtract(1)\n",
    "\n",
    "        Map.addLayer(FCD2_1, {'min':0 ,'max':80, 'palette':['ff4c16', 'ffd96c', '39a71d']}, 'FCD2_1')\n",
    "        #Map.addLayer(FCD2_1.mask(FCD2_1.gte(30)), {'min':0 ,'max':80, 'palette':['ff4c16', 'ffd96c', '39a71d']}, 'FCD2_1_morethan30')\n",
    "        print('finish processing PCA please continue')\n",
    "        \n",
    "    else:\n",
    "        print('no thermal band, choosing planet lab nicfi images')\n",
    "        si = si_norm\n",
    "        #minsi =si.reduceRegion(reducer=ee.Reducer.min(),geometry=AOI,scale=1000,bestEffort=True,tileScale=16)\n",
    "        #minsi = ee.Dictionary(minsi).toImage()\n",
    "        #maxsi =si.reduceRegion(reducer=ee.Reducer.max(),geometry=AOI,scale=1000,bestEffort=True,tileScale=16)\n",
    "        #maxsi = ee.Dictionary(maxsi).toImage()\n",
    "\n",
    "        #ssiscale = si.subtract(minsi).divide(maxsi.subtract(minsi)).multiply(100)\n",
    "        #print(ssiscale, 'SSI')\n",
    "        Map.addLayer(si,{'min':0, 'max':100}, 'SSI')\n",
    "\n",
    "        print('Now calculating the FCD from SVI and SSI - selecting band svi1 svi2 ssi1 and ssi2')\n",
    "        svi1 = SVI.select(['VD1'])\n",
    "        ssi1 = si.select(['SI'])\n",
    "        svi2 = SVI.select(['VD2'])\n",
    "\n",
    "        # Starting to include in the formula for Forest Cover Density\n",
    "        FCD1_1 = (((svi1.multiply(ssi1)).add(1)).pow(0.5)).subtract(1)\n",
    "        Map.addLayer(FCD1_1, {'min':0 ,'max':80, 'palette':['ff4c16', 'ffd96c', '39a71d']}, 'FCD1_1')\n",
    "        #Map.addLayer(FCD1.mask(FCD1.gte(30)), {'min':0 ,'max':80, 'palette':['ff4c16', 'ffd96c', '39a71d']}, 'FCD1_morethan30')\n",
    "\n",
    "\n",
    "        print('Now calculating the FCD from SVI2 and SSI1 into FCD in percentage')\n",
    "        # The best on AOI_B30 based on the visual check, combination svi2 and ssi1\n",
    "        FCD2_1 = (((svi2.multiply(ssi1)).add(1)).pow(0.5)).subtract(1)\n",
    "\n",
    "        Map.addLayer(FCD2_1, {'min':0 ,'max':80, 'palette':['ff4c16', 'ffd96c', '39a71d']}, 'FCD2_1')\n",
    "        #Map.addLayer(FCD2_1.mask(FCD2_1.gte(30)), {'min':0 ,'max':80, 'palette':['ff4c16', 'ffd96c', '39a71d']}, 'FCD2_1_morethan30')\n",
    "        print('finish processing PCA please continue')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4efc7c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success calculating FCD best combination, and added to the map\n",
      "Now we label the FCD\n",
      "Adding the map of Forest, FCD >= 50% and mask only if not water in area (hansen) and NDWI\n",
      "Adding the map of Shrubland, FCD <  50% and FCD >= 30%\n",
      "Adding the map of Grassland or Openland, FCD  < 30%\n",
      "Processing - the zoning classification\n",
      "Process finish kindly check the map\n"
     ]
    }
   ],
   "source": [
    "## BASELINE SELECTION FOREST\n",
    "# run if arief et al for main data, or additional of hansen based\n",
    "if algor_process == 'Sentinel' or algor_process == 'Hansen':\n",
    "    hiforest_masked = applying_sentinel_forest(s2_sr_median,ndvi_hi,bi_hi,si_hi,pixels)\n",
    "\n",
    "# run if arief et al for main data, or additional of hansen based\n",
    "if algor_process == 'arief_hansen' or algor_process == 'hansen_arief':\n",
    "    image_y_highbaseline = apply_arief_equation(s2_sr_median, y_threshold)\n",
    "\n",
    "# processing if fcd used    \n",
    "if algor_process == 'fcd_galcit':\n",
    "    FCD = FCD2_1\n",
    "    \n",
    "    print('Success calculating FCD best combination, and added to the map')\n",
    "    print('Now we label the FCD')\n",
    "    # Starting to create threshold for labeling\n",
    "    WaterMask = gfc.select(['datamask']).rename('datamask').eq(2)\n",
    "    WaterinAOI = AOI_img.mask().updateMask(WaterMask)\n",
    "    # unmasked the water (hansen)\n",
    "    unmaskedWaterAOI = AOI_img.unmask().updateMask(WaterinAOI.mask().Not()).clip(AOI)\n",
    "    \n",
    "    ######### Zone 5: Water Body - NDWI Sentinel\n",
    "    # from a function, output is already assigned in a band name: Class : 5\n",
    "    #water_list = applying_sentinel_water(image_corrected, ndwi_hi)\n",
    "    #waterinAOI_ndwi = water_list[0]\n",
    "    #unmaskedWaterAOI_ndwi = AOI_img.unmask().updateMask(waterinAOI_ndwi.mask().Not()).clip(AOI)\n",
    "    \n",
    "    \n",
    "    print(f'Adding the map of Forest, FCD >= {yrf_forest}% and mask only if not water in area (hansen) and NDWI')\n",
    "    #Forest\n",
    "    AllForest = FCD.mask(FCD.gte(yrf_forest).And(unmaskedWaterAOI))\n",
    "    HighForestDense = FCD.mask(FCD.gte(high_forest).And(unmaskedWaterAOI))\n",
    "    YRFForestDense = FCD.mask(FCD.gte(yrf_forest).And(unmaskedWaterAOI).And(FCD.lt(high_forest)))\n",
    "    Map.addLayer(HighForestDense, {'min':0 ,'max':100}, f'Forest (FCD >= {high_forest}%)')\n",
    "    \n",
    "    Map.addLayer(YRFForestDense, {'min':0 ,'max':100}, f'Forest (FCD >= {yrf_forest}%) and < {high_forest}%')\n",
    "    \n",
    "    print(f'Adding the map of Shrubland, FCD <  {yrf_forest}% and FCD >= {shrub_grass}%')\n",
    "    #Shrubland\n",
    "    Shrubland = FCD.mask(FCD.lt(yrf_forest).And(FCD.gte(shrub_grass)).And(unmaskedWaterAOI))\n",
    "    Map.addLayer(Shrubland, {'min':0 ,'max':100}, f'Shrubland ({shrub_grass}% <= FCD < {yrf_forest}%)')\n",
    "    \n",
    "    print(f'Adding the map of Grassland or Openland, FCD  < {shrub_grass}%')\n",
    "    #Grassland / openland\n",
    "    Grassland = FCD.mask(FCD.lt(shrub_grass).And(unmaskedWaterAOI))\n",
    "    Map.addLayer(Grassland, {'min':0 ,'max':100}, f'Grassland (FCD < {shrub_grass})')\n",
    "    \n",
    "    hiforest_masked = AllForest\n",
    "    #Shrubland   \n",
    "    #Grassland\n",
    "    \n",
    "    print('Processing - the zoning classification')\n",
    "    highForestOnly = ee.Image(assigning_band(band_name_image,1,hiforest_masked.clip(AOI)))\n",
    "    Map.addLayer(highForestOnly,{'bands': ['Class'],'palette':hi_forest},f'ALL_Forest_FCD > {yrf_forest}% - Class 1')\n",
    "    tiff_result = applying_zone_sentinel_hansen(hiforest_masked,minLoss,image_corrected, ndwi_hi)\n",
    "    band_names_ref = 'Forest_Lan' #this band_names refer to the name of column in shapefile - which column that refer as point reference value\n",
    "    if eval_process: \n",
    "        eval = eval_accuracy(band_names_ref, band_name_image,highForestOnly)\n",
    "    \n",
    "    print('Process finish kindly check the map')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec26a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "    \n",
    "# Starting process every other Option algorithm beside FCD\n",
    "if algor_process == 'Sentinel':\n",
    "    highForestOnly = ee.Image(assigning_band(band_name_image,1,hiforest_masked.clip(AOI)))\n",
    "    Map.addLayer(highForestOnly,{'bands': ['Class'],'palette':hi_forest},'High_Forest_SENTINEL_Assigned - Class 1')\n",
    "    tiff_result = applying_zone_sentinel_hansen(hiforest_masked,minLoss,s2_sr_median, ndwi_hi)\n",
    "    band_names_ref = 'Forest_Sen' #this band_names refer to the name of column in shapefile - which column that refer as point reference value\n",
    "    if eval_process: \n",
    "        eval = eval_accuracy(band_names_ref, band_name_image,highForestOnly)\n",
    "    \n",
    "elif algor_process == 'Hansen':\n",
    "    band_names_ref = 'Forest_Lan' #this band_names refer to the name of column in shapefile - which column that refer as point reference value\n",
    "     \n",
    "    ## Version 2 - Hansen - Sentinel\n",
    "    \n",
    "    ## Zone 4: 10 Years rule not OK - > CC overlay with TCL, (Tree Crown Cover) more than the threshold in AOI\n",
    "    tenYearsRule = minLoss.clip(AOI)\n",
    "    tenYearsRule_edited = ee.Image(assigning_band(band_name_image,4,tenYearsRule))\n",
    "    Map.addLayer(tenYearsRule_edited,{'bands': ['Class'],'palette': '#FFA500'},\"10 Years Rule - not OK\")\n",
    "    \n",
    "    \n",
    "    ## Zone 3: Forest (Sentinel) passed 10 years rule not OK - TCL before year_start_loss overlay with > CC\n",
    "    # Direct process to get the < year_rule TCL (Explicit)\n",
    "    #treeLossYear = gfc.select(['lossyear'])\n",
    "    treeLoss_lessYear = treeLossYear.lt(year_start_loss).selfMask()\n",
    "    CC_lessYearloss_overlay = AOI_img.And(minArea.And(treeLoss_lessYear))\n",
    "    # obtain area ten years < CC with the forest masked (Sentinel)\n",
    "    ForestRegenerating_lessYear = hiforest_masked.And(CC_lessYearloss_overlay)\n",
    "    ForestRegenerating_lessYear_edited = ee.Image(assigning_band(band_name_image,3,ForestRegenerating_lessYear))\n",
    "\n",
    "    Map.addLayer(ForestRegenerating_lessYear_edited,{'bands': ['Class'],'palette': '#FF0000'},f\"Forest (Sentinel) Regenerating - TCL < 20{year_start_loss}\")\n",
    "   \n",
    "    ## Zone 5: Water Body Based on Hansen Data\n",
    "    WaterMask = gfc.select(['datamask']).rename('datamask').eq(2)\n",
    "    WaterAOI = AOI_img.mask().updateMask(WaterMask)\n",
    "    # assigning band Class in WaterBody\n",
    "    water_edited = ee.Image(assigning_band(band_name_image,5,WaterAOI))\n",
    "\n",
    "    Map.addLayer(water_edited,{'bands': ['Class'],'palette': water},\"Water in AOI\")\n",
    "    \n",
    "    # unmasked the water\n",
    "    unmaskedWaterAOI = AOI_img.unmask().updateMask(WaterAOI.mask().Not()).clip(AOI)\n",
    "    \n",
    "    # Zone 1: Go Zone - No Forest (Sentinel) < start_loss_year in CC\n",
    "    hiFMasked = hiforest_masked.mask()\n",
    "    maskedHiFI_inverted = hiFMasked.Not()\n",
    "    unmaskedHiF = AOI_img.unmask().updateMask(maskedHiFI_inverted).clip(AOI)\n",
    "    GoZoneNoForest_TCL_lessYear = unmaskedHiF.And(CC_lessYearloss_overlay).And(unmaskedWaterAOI)\n",
    "    GoZoneNoForest_TCL_lessYear_edited = ee.Image(assigning_band(band_name_image,1,GoZoneNoForest_TCL_lessYear))\n",
    "\n",
    "    Map.addLayer(GoZoneNoForest_TCL_lessYear_edited,{'bands': ['Class'],'palette': '#FFFF00'},\"Go Zone - No Forest (Sentinel) in TCL less year >CC\")\n",
    "\n",
    "    ''' #Implying the same as year < year_start_loss and minArea\n",
    "    ## Zone 3: Forest (Sentinel) 10 years rule not OK - TCL Overlaid with < CC, (Tree Crown Cover) less than the threshold in AOI\n",
    "    # helper - mask\n",
    "    tenYearsRule_mask = tenYearsRule.mask()\n",
    "    masktenYearsRule_inverted = tenYearsRule_mask.Not()\n",
    "    # Unmasked ten years all - all area outside ten years rule (> CC)\n",
    "    unmaskedtenYrRuleALL = AOI_img.unmask().updateMask(masktenYearsRule_inverted).clip(AOI)\n",
    "    # tree loss in the AOI\n",
    "    tenYearsRuleAll = AOI_img.And(treeLoss)\n",
    "    # obtain the area in outside ten years rule (>CC) intersected with all ten years rule -> tcl in < CC\n",
    "    tenYearsRule_notCC = tenYearsRuleAll.And(unmaskedtenYrRuleALL)\n",
    "    # obtain area ten years < CC with the forest masked (Sentinel)\n",
    "    Forest10Years_noCC = hiforest_masked.And(tenYearsRule_notCC)\n",
    "    Forest10Years_noCC_edited = ee.Image(assigning_band(band_name_image,3,Forest10Years_noCC))\n",
    "\n",
    "    Map.addLayer(Forest10Years_noCC_edited,{'bands': ['Class'],'palette': '#32a844'},\"Forest (Sentinel) 10 Years < CC\")\n",
    "\n",
    "\n",
    "    # Zone 1: Go Zone - No Forest (Sentinel) in TCL < CC\n",
    "    hiFMasked = hiforest_masked.mask()\n",
    "    maskedHiFI_inverted = hiFMasked.Not()\n",
    "    unmaskedHiF = AOI_img.unmask().updateMask(maskedHiFI_inverted).clip(AOI)\n",
    "    GoZoneNoForest_TCLnoCC = unmaskedHiF.And(tenYearsRule_notCC)\n",
    "    GoZoneNoForest_TCLnoCC_edited = ee.Image(assigning_band(band_name_image,1,GoZoneNoForest_TCLnoCC))\n",
    "\n",
    "    Map.addLayer(GoZoneNoForest_TCLnoCC_edited,{'bands': ['Class'],'palette': '#FFFF00'},\"Go Zone - No Forest (Sentinel) in TCL < CC\")\n",
    "    '''\n",
    "    \n",
    "    ## Zone 2: Forest (Hansen > CC year 2000 Baseline) does not overlay with TCL (ALL)\n",
    "    # helper - unmasked, get area only outside all the ten years rule TCL (ALL)\n",
    "    # tree loss in the AOI and exclude no loss\n",
    "    treeLossAll = treeLossYear.gt(0).selfMask()\n",
    "    #Map.addLayer(treeLossAll,{},'treelossall', False)\n",
    "    tenYearsRuleAll = AOI_img.And(treeLossAll)\n",
    "    masked_tenYearsRuleAll = tenYearsRuleAll.mask()\n",
    "    masked_inverted_tenYearsRuleAll = masked_tenYearsRuleAll.Not()\n",
    "    unmasked_tenYearsRuleAll = AOI_img.unmask().updateMask(masked_inverted_tenYearsRuleAll).clip(AOI)\n",
    "    # get the area that is forest in 2000 and has no TCL (No overlay with TCL ALL)\n",
    "    Forest_RecentHansen = ForestArea2000Hansen.And(unmasked_tenYearsRuleAll)\n",
    "    # assigning the number Class - 2\n",
    "    Forest_RecentHansen_edited = ee.Image(assigning_band(band_name_image,2,Forest_RecentHansen))\n",
    "    Map.addLayer(Forest_RecentHansen_edited,{'bands': ['Class'],'palette': hi_forest},f\"Forest_{END_DATE} - Hansen (No TCL in Forest 2000 until {END_DATE}) to be evaluated\")\n",
    "\n",
    "    # Zone 3 - Forest (Sentinel) < CC (ALL TCL)\n",
    "    # less than threshold\n",
    "    canopyCover_lessThreshold = canopyCover.lt(cc).selfMask()\n",
    "    Forest_Regenerating_lessCC = hiforest_masked.And(canopyCover_lessThreshold).And(AOI_img)\n",
    "    Forest_Regenerating_lessCC_edited = ee.Image(assigning_band(band_name_image,3,Forest_Regenerating_lessCC))\n",
    "    Map.addLayer(Forest_Regenerating_lessCC_edited,{'bands': ['Class'],'palette': '#FF0000'},f\"Forest (Sentinel) CC < {tree_cover_forest}% - Regenerating\")\n",
    "\n",
    "    # Zone 1 - Go Zone area (No Forest (Sentinel) and < CC)\n",
    "    GoZone_NoForestSen_lessThreshold = unmaskedHiF.And(canopyCover_lessThreshold).And(unmaskedWaterAOI)\n",
    "    GoZone_NoForestSen_lessThreshold_edited = ee.Image(assigning_band(band_name_image,1,GoZone_NoForestSen_lessThreshold))\n",
    "    Map.addLayer(GoZone_NoForestSen_lessThreshold_edited,{'bands': ['Class'],'palette': '#FFFF00'},\"Go Zone - No Forest (Sentinel) < CC\")\n",
    "    \n",
    "\n",
    "    if eval_process:\n",
    "        print(f\"EVALUATING ONLY IN FOREST AREA CC > {tree_cover_forest}% THAT GENERATED BY HANSEN 2000 THAT HAS NO TCL\")\n",
    "        ### EVALUATING FOREST CLASS HANSEN\n",
    "        # CHANGE THE NUMBER Class into 1 as Forest for evaluation purpose only\n",
    "        Forest_RecentHansen_edited_Class1_Forest = ee.Image(assigning_band(band_name_image,1,Forest_RecentHansen))\n",
    "        print(\"Evaluating only Hansen Forest\")\n",
    "        eval = eval_accuracy(band_names_ref, band_name_image,Forest_RecentHansen_edited_Class1_Forest)   \n",
    "        print(\"---------------------------- \\n\")\n",
    "\n",
    "        ### Evaluating the all end Result Forest Classified (Hansen + Sentinel)\n",
    "\n",
    "        def get_matrix(image, band_name_image):\n",
    "            band = image.select([band_name_image])\n",
    "\n",
    "            # Unmask the band, replacing masked values (null) - Class: null with 0\n",
    "            unmasked_band = band.unmask(0)\n",
    "\n",
    "            # Use sampleRegions to extract pixel values at the point locations\n",
    "            sampled_points = unmasked_band.sampleRegions(\n",
    "                collection=ref_point_loc,\n",
    "                scale=10\n",
    "            )\n",
    "\n",
    "            pixel_values = sampled_points.aggregate_array(band_name_image).getInfo()\n",
    "\n",
    "            return pixel_values\n",
    "\n",
    "        ref_values = gdf_ref[band_names_ref].values\n",
    "\n",
    "        # prepare for all class into 1, for matrix number assign as forest is 1, no forest is 0, assumed they are not overlapped\n",
    "        print(f\"Evaluating All Forest Classified (Hansen CC > {tree_cover_forest}%) + Sentinel (inGAP) vs Reference value\")\n",
    "        # in the end, if one of them classified forest, then the all result will be class: 1\n",
    "        ForestRegenerating_lessYear_eval = ee.Image(assigning_band(band_name_image,1,ForestRegenerating_lessYear))   \n",
    "        Forest_Regenerating_lessCC_eval = ee.Image(assigning_band(band_name_image,1,Forest_Regenerating_lessCC))\n",
    "\n",
    "        #all_Forest_Hansen_Sentinel = [Forest_RecentHansen_edited_Class1_Forest,ForestRegenerating_lessYear_eval,Forest_Regenerating_lessCC_eval]\n",
    "\n",
    "        HansenForestOnly_pixValue = get_matrix(Forest_RecentHansen_edited_Class1_Forest, band_name_image)\n",
    "        print(f\"Hansen pix no Loss in CC > {tree_cover_forest}%\", HansenForestOnly_pixValue)\n",
    "        ForestRegenerating_lessYear_pixValue = get_matrix(ForestRegenerating_lessYear_eval, band_name_image)\n",
    "        print(f\"Forest (Sentinel) pix in TCL year < 20{year_start_loss}\",ForestRegenerating_lessYear_pixValue)\n",
    "        Forest_Regenerating_lessCC_pixValue = get_matrix(Forest_Regenerating_lessCC_eval, band_name_image)\n",
    "        print(f\"Forest (Sentinel) pix in CC (year 2000) < {tree_cover_forest}% - Regenerating\",Forest_Regenerating_lessCC_pixValue)\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "        a = np.array(HansenForestOnly_pixValue)\n",
    "        b = np.array(ForestRegenerating_lessYear_pixValue)\n",
    "        c = np.array(Forest_Regenerating_lessCC_pixValue)\n",
    "\n",
    "        AllForestArr = a + b + c\n",
    "        AllForestArr_list = AllForestArr.tolist()\n",
    "\n",
    "        print(\"Reference Value: \", ref_values)\n",
    "        print(\"Pixel Value (All Forest): \",AllForestArr_list)\n",
    "\n",
    "        confusion_mat_all = confusion_matrix(ref_values, AllForestArr_list)\n",
    "        print(\"Confusion matrix summary: \\n\", confusion_mat_all)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(ref_values, AllForestArr_list).ravel()\n",
    "\n",
    "        print(\"TN:\",tn,\"\\n FP:\",fp, \"\\n FN:\",fn, \"\\n TP:\",tp)\n",
    "\n",
    "        accuracy = ((tp + tn) / (tp + tn + fp + fn))*100.00\n",
    "        print(\"Accuracy: (%) \",accuracy)\n",
    "\n",
    "        precision = (tp / (tp + fp))*100.00\n",
    "        print(\"Precision: (%) \",precision)\n",
    "\n",
    "        prod_acc = (tp / (tp + fn))*100.00\n",
    "        print(\"Producer Accuracy: (%) \",prod_acc) #means that how is the raster result (image) predict forest only,\n",
    "\n",
    "        user_acc = (tn / (tn + fp))*100.00\n",
    "        print(\"User Accuracy: (%) \",user_acc)\n",
    "        \n",
    "        \n",
    "    labels = [f'Forest_{END_DATE} - Hansen (No TCL in Forest 2000 until {END_DATE})', \n",
    "          f'Forest (Sentinel) Regenerating - TCL < 20{year_start_loss}', \n",
    "          f\"Forest (Sentinel) CC < {tree_cover_forest}% - Regenerating\",\n",
    "          \"10 Years Rule - not OK\",\n",
    "          'Water', \n",
    "          'Go Zone',\n",
    "         ]\n",
    "    # colorS can be defined using either hex code or RGB (0-255, 0-255, 0-255)\n",
    "    colors = [hi_forest, \n",
    "              '#FF0000', \n",
    "              '#FF0000', \n",
    "              '#FFA500', \n",
    "               water,\n",
    "              '#FFFF00',\n",
    "             ]\n",
    "    # legend_colors = [(255, 0, 0), (127, 255, 0), (127, 18, 25), (36, 70, 180), (96, 68 123)]\n",
    "\n",
    "    Map.add_legend(title='Legend', labels=labels, colors=colors)\n",
    "\n",
    "elif algor_process == 'arief_hansen':\n",
    "    highForestOnly = ee.Image(assigning_band(band_name_image,1,image_y_highbaseline.clip(AOI)))\n",
    "    Map.addLayer(highForestOnly,{'bands': ['Class'],'palette':hi_forest},'High_Forest_SENTINEL_Assigned_Arief - Class 1')\n",
    "    tiff_result = applying_zone_sentinel_hansen(image_y_highbaseline,minLoss,s2_sr_median, ndwi_hi)\n",
    "    band_names_ref = 'Forest_Sen' #this band_names refer to the name of column in shapefile - which column that refer as point reference value\n",
    "    if eval_process: \n",
    "        eval = eval_accuracy(band_names_ref, band_name_image,highForestOnly)\n",
    "        \n",
    "elif algor_process == 'hansen_arief':\n",
    "    band_names_ref = 'Forest_Lan' #this band_names refer to the name of column in shapefile - which column that refer as point reference value\n",
    "     \n",
    "    ## Version 2 - Hansen - Sentinel\n",
    "    \n",
    "    ## Zone 4: 10 Years rule not OK - > CC overlay with TCL, (Tree Crown Cover) more than the threshold in AOI\n",
    "    tenYearsRule = minLoss.clip(AOI)\n",
    "    tenYearsRule_edited = ee.Image(assigning_band(band_name_image,4,tenYearsRule))\n",
    "    Map.addLayer(tenYearsRule_edited,{'bands': ['Class'],'palette': '#FFA500'},\"10 Years Rule - not OK\")\n",
    "    \n",
    "    \n",
    "    ## Zone 3: Forest (Sentinel) passed 10 years rule not OK - TCL before year_start_loss overlay with > CC\n",
    "    # Direct process to get the < year_rule TCL (Explicit)\n",
    "    #treeLossYear = gfc.select(['lossyear'])\n",
    "    treeLoss_lessYear = treeLossYear.lt(year_start_loss).selfMask()\n",
    "    CC_lessYearloss_overlay = AOI_img.And(minArea.And(treeLoss_lessYear))\n",
    "    # obtain area ten years < CC with the forest masked (Sentinel)\n",
    "    ForestRegenerating_lessYear = image_y_highbaseline.And(CC_lessYearloss_overlay)\n",
    "    ForestRegenerating_lessYear_edited = ee.Image(assigning_band(band_name_image,3,ForestRegenerating_lessYear))\n",
    "\n",
    "    Map.addLayer(ForestRegenerating_lessYear_edited,{'bands': ['Class'],'palette': '#FF0000'},f\"Forest (Sentinel) Regenerating - TCL < 20{year_start_loss}\")\n",
    "\n",
    "    ## Zone 5: Water Body Based on Hansen Data\n",
    "    WaterMask = gfc.select(['datamask']).rename('datamask').eq(2)\n",
    "    WaterAOI = AOI_img.mask().updateMask(WaterMask)\n",
    "    # assigning band Class in WaterBody\n",
    "    water_edited = ee.Image(assigning_band(band_name_image,5,WaterAOI))\n",
    "\n",
    "    Map.addLayer(water_edited,{'bands': ['Class'],'palette': water},\"Water in AOI\")\n",
    "    \n",
    "    # unmasked the water\n",
    "    unmaskedWaterAOI = AOI_img.unmask().updateMask(WaterAOI.mask().Not()).clip(AOI)\n",
    "    \n",
    "    # Zone 1: Go Zone - No Forest (Sentinel) < start_loss_year in CC\n",
    "    hiFMasked = image_y_highbaseline.mask()\n",
    "    maskedHiFI_inverted = hiFMasked.Not()\n",
    "    unmaskedHiF = AOI_img.unmask().updateMask(maskedHiFI_inverted).clip(AOI)\n",
    "    GoZoneNoForest_TCL_lessYear = unmaskedHiF.And(CC_lessYearloss_overlay).And(unmaskedWaterAOI)\n",
    "    GoZoneNoForest_TCL_lessYear_edited = ee.Image(assigning_band(band_name_image,1,GoZoneNoForest_TCL_lessYear))\n",
    "\n",
    "    Map.addLayer(GoZoneNoForest_TCL_lessYear_edited,{'bands': ['Class'],'palette': '#FFFF00'},\"Go Zone - No Forest (Sentinel) in TCL less year >CC\")\n",
    "\n",
    "    ''' #Implying the same as year < year_start_loss and minArea\n",
    "    ## Zone 3: Forest (Sentinel) 10 years rule not OK - TCL Overlaid with < CC, (Tree Crown Cover) less than the threshold in AOI\n",
    "    # helper - mask\n",
    "    tenYearsRule_mask = tenYearsRule.mask()\n",
    "    masktenYearsRule_inverted = tenYearsRule_mask.Not()\n",
    "    # Unmasked ten years all - all area outside ten years rule (> CC)\n",
    "    unmaskedtenYrRuleALL = AOI_img.unmask().updateMask(masktenYearsRule_inverted).clip(AOI)\n",
    "    # tree loss in the AOI\n",
    "    tenYearsRuleAll = AOI_img.And(treeLoss)\n",
    "    # obtain the area in outside ten years rule (>CC) intersected with all ten years rule -> tcl in < CC\n",
    "    tenYearsRule_notCC = tenYearsRuleAll.And(unmaskedtenYrRuleALL)\n",
    "    # obtain area ten years < CC with the forest masked (Sentinel)\n",
    "    Forest10Years_noCC = hiforest_masked.And(tenYearsRule_notCC)\n",
    "    Forest10Years_noCC_edited = ee.Image(assigning_band(band_name_image,3,Forest10Years_noCC))\n",
    "\n",
    "    Map.addLayer(Forest10Years_noCC_edited,{'bands': ['Class'],'palette': '#32a844'},\"Forest (Sentinel) 10 Years < CC\")\n",
    "\n",
    "\n",
    "    # Zone 1: Go Zone - No Forest (Sentinel) in TCL < CC\n",
    "    hiFMasked = hiforest_masked.mask()\n",
    "    maskedHiFI_inverted = hiFMasked.Not()\n",
    "    unmaskedHiF = AOI_img.unmask().updateMask(maskedHiFI_inverted).clip(AOI)\n",
    "    GoZoneNoForest_TCLnoCC = unmaskedHiF.And(tenYearsRule_notCC)\n",
    "    GoZoneNoForest_TCLnoCC_edited = ee.Image(assigning_band(band_name_image,1,GoZoneNoForest_TCLnoCC))\n",
    "\n",
    "    Map.addLayer(GoZoneNoForest_TCLnoCC_edited,{'bands': ['Class'],'palette': '#FFFF00'},\"Go Zone - No Forest (Sentinel) in TCL < CC\")\n",
    "    '''\n",
    "    \n",
    "    ## Zone 2: Forest (Hansen > CC year 2000 Baseline) does not overlay with TCL (ALL)\n",
    "    # helper - unmasked, get area only outside all the ten years rule TCL (ALL)\n",
    "    # tree loss in the AOI and exclude no loss\n",
    "    treeLossAll = treeLossYear.gt(0).selfMask()\n",
    "    #Map.addLayer(treeLossAll,{},'treelossall',False)\n",
    "    tenYearsRuleAll = AOI_img.And(treeLossAll)\n",
    "    masked_tenYearsRuleAll = tenYearsRuleAll.mask()\n",
    "    masked_inverted_tenYearsRuleAll = masked_tenYearsRuleAll.Not()\n",
    "    unmasked_tenYearsRuleAll = AOI_img.unmask().updateMask(masked_inverted_tenYearsRuleAll).clip(AOI)\n",
    "    # get the area that is forest in 2000 and has no TCL (No overlay with TCL ALL)\n",
    "    Forest_RecentHansen = ForestArea2000Hansen.And(unmasked_tenYearsRuleAll)\n",
    "    # assigning the number Class - 2\n",
    "    Forest_RecentHansen_edited = ee.Image(assigning_band(band_name_image,2,Forest_RecentHansen))\n",
    "    Map.addLayer(Forest_RecentHansen_edited,{'bands': ['Class'],'palette': hi_forest},f\"Forest_{END_DATE} - Hansen (No TCL in Forest 2000 until {END_DATE}) to be evaluated\")\n",
    "\n",
    "    # Zone 3 - Forest (Sentinel) < CC (ALL TCL)\n",
    "    # less than threshold\n",
    "    canopyCover_lessThreshold = canopyCover.lt(cc).selfMask()\n",
    "    Forest_Regenerating_lessCC = image_y_highbaseline.And(canopyCover_lessThreshold).And(AOI_img)\n",
    "    Forest_Regenerating_lessCC_edited = ee.Image(assigning_band(band_name_image,3,Forest_Regenerating_lessCC))\n",
    "    Map.addLayer(Forest_Regenerating_lessCC_edited,{'bands': ['Class'],'palette': '#FF0000'},f\"Forest (Sentinel) CC < {tree_cover_forest}% - Regenerating\")\n",
    "\n",
    "    # Zone 1 - Go Zone area (No Forest (Sentinel) and < CC)\n",
    "    GoZone_NoForestSen_lessThreshold = unmaskedHiF.And(canopyCover_lessThreshold).And(unmaskedWaterAOI)\n",
    "    GoZone_NoForestSen_lessThreshold_edited = ee.Image(assigning_band(band_name_image,1,GoZone_NoForestSen_lessThreshold))\n",
    "    Map.addLayer(GoZone_NoForestSen_lessThreshold_edited,{'bands': ['Class'],'palette': '#FFFF00'},\"Go Zone - No Forest (Sentinel) < CC\")\n",
    "\n",
    "    if eval_process:\n",
    "        print(f\"EVALUATING ONLY IN FOREST AREA CC > {tree_cover_forest}% THAT GENERATED BY HANSEN 2000 THAT HAS NO TCL\")\n",
    "        ### EVALUATING FOREST CLASS HANSEN\n",
    "        # CHANGE THE NUMBER Class into 1 as Forest for evaluation purpose only\n",
    "        Forest_RecentHansen_edited_Class1_Forest = ee.Image(assigning_band(band_name_image,1,Forest_RecentHansen))\n",
    "        print(\"Evaluating only Hansen Forest\")\n",
    "        eval = eval_accuracy(band_names_ref, band_name_image,Forest_RecentHansen_edited_Class1_Forest)   \n",
    "        print(\"---------------------------- \\n\")\n",
    "\n",
    "        ### Evaluating the all end Result Forest Classified (Hansen + Sentinel)\n",
    "\n",
    "        def get_matrix(image, band_name_image):\n",
    "            band = image.select([band_name_image])\n",
    "\n",
    "            # Unmask the band, replacing masked values (null) - Class: null with 0\n",
    "            unmasked_band = band.unmask(0)\n",
    "\n",
    "            # Use sampleRegions to extract pixel values at the point locations\n",
    "            sampled_points = unmasked_band.sampleRegions(\n",
    "                collection=ref_point_loc,\n",
    "                scale=10\n",
    "            )\n",
    "\n",
    "            pixel_values = sampled_points.aggregate_array(band_name_image).getInfo()\n",
    "\n",
    "            return pixel_values\n",
    "\n",
    "        ref_values = gdf_ref[band_names_ref].values\n",
    "\n",
    "        # prepare for all class into 1, for matrix number assign as forest is 1, no forest is 0, assumed they are not overlapped\n",
    "        print(f\"Evaluating All Forest Classified (Hansen CC > {tree_cover_forest}%) + Sentinel (inGAP) vs Reference value\")\n",
    "        # in the end, if one of them classified forest, then the all result will be class: 1\n",
    "        ForestRegenerating_lessYear_eval = ee.Image(assigning_band(band_name_image,1,ForestRegenerating_lessYear))   \n",
    "        Forest_Regenerating_lessCC_eval = ee.Image(assigning_band(band_name_image,1,Forest_Regenerating_lessCC))\n",
    "\n",
    "        #all_Forest_Hansen_Sentinel = [Forest_RecentHansen_edited_Class1_Forest,ForestRegenerating_lessYear_eval,Forest_Regenerating_lessCC_eval]\n",
    "\n",
    "        HansenForestOnly_pixValue = get_matrix(Forest_RecentHansen_edited_Class1_Forest, band_name_image)\n",
    "        print(f\"Hansen pix no Loss in CC > {tree_cover_forest}%\", HansenForestOnly_pixValue)\n",
    "        ForestRegenerating_lessYear_pixValue = get_matrix(ForestRegenerating_lessYear_eval, band_name_image)\n",
    "        print(f\"Forest (Sentinel) pix in TCL year < 20{year_start_loss}\",ForestRegenerating_lessYear_pixValue)\n",
    "        Forest_Regenerating_lessCC_pixValue = get_matrix(Forest_Regenerating_lessCC_eval, band_name_image)\n",
    "        print(f\"Forest (Sentinel) pix in CC (year 2000) < {tree_cover_forest}% - Regenerating\",Forest_Regenerating_lessCC_pixValue)\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "        a = np.array(HansenForestOnly_pixValue)\n",
    "        b = np.array(ForestRegenerating_lessYear_pixValue)\n",
    "        c = np.array(Forest_Regenerating_lessCC_pixValue)\n",
    "\n",
    "        AllForestArr = a + b + c\n",
    "        AllForestArr_list = AllForestArr.tolist()\n",
    "\n",
    "        print(\"Reference Value: \", ref_values)\n",
    "        print(\"Pixel Value (All Forest): \",AllForestArr_list)\n",
    "\n",
    "        confusion_mat_all = confusion_matrix(ref_values, AllForestArr_list)\n",
    "        print(\"Confusion matrix summary: \\n\", confusion_mat_all)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(ref_values, AllForestArr_list).ravel()\n",
    "\n",
    "        print(\"TN:\",tn,\"\\n FP:\",fp, \"\\n FN:\",fn, \"\\n TP:\",tp)\n",
    "\n",
    "        accuracy = ((tp + tn) / (tp + tn + fp + fn))*100.00\n",
    "        print(\"Accuracy: (%) \",accuracy)\n",
    "\n",
    "        precision = (tp / (tp + fp))*100.00\n",
    "        print(\"Precision: (%) \",precision)\n",
    "\n",
    "        prod_acc = (tp / (tp + fn))*100.00\n",
    "        print(\"Producer Accuracy: (%) \",prod_acc) #means that how is the raster result (image) predict forest only,\n",
    "\n",
    "        user_acc = (tn / (tn + fp))*100.00\n",
    "        print(\"User Accuracy: (%) \",user_acc)\n",
    "        \n",
    "        \n",
    "    labels = [f'Forest_{END_DATE} - Hansen (No TCL in Forest 2000 until {END_DATE})', \n",
    "          f'Forest (Sentinel) Regenerating - TCL < 20{year_start_loss}', \n",
    "          f\"Forest (Sentinel) CC < {tree_cover_forest}% - Regenerating\",\n",
    "          \"10 Years Rule - not OK\",\n",
    "          'Water', \n",
    "          'Go Zone',\n",
    "         ]\n",
    "    # colorS can be defined using either hex code or RGB (0-255, 0-255, 0-255)\n",
    "    colors = [hi_forest, \n",
    "              '#FF0000', \n",
    "              '#FF0000', \n",
    "              '#FFA500', \n",
    "               water,\n",
    "              '#FFFF00',\n",
    "             ]\n",
    "    # legend_colors = [(255, 0, 0), (127, 255, 0), (127, 18, 25), (36, 70, 180), (96, 68 123)]\n",
    "\n",
    "    Map.add_legend(title='Legend', labels=labels, colors=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e433ecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "if small_aoi:\n",
    "    #create visual boundary color only\n",
    "    empty = ee.Image().byte()\n",
    "    AOIm_small = empty.paint(AOIsmall,0,10)\n",
    "\n",
    "    #Map.addLayer(AOIm,{'palette': '#e043f3'},'AOI') #still buggy\n",
    "    Map.addLayer(AOIm_small,{},'AOIm_small')\n",
    "    \n",
    "if smaller_aoi:\n",
    "    #create visual boundary color only\n",
    "    empty = ee.Image().byte()\n",
    "    AOIm_smaller = empty.paint(AOIsmaller,0,10)\n",
    "\n",
    "    #Map.addLayer(AOIm,{'palette': '#e043f3'},'AOI') #still buggy\n",
    "    Map.addLayer(AOIm_smaller,{},'AOIm_smaller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9703ca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick checking if needed, to uncomment\n",
    "#water_list = applying_sentinel_water(filtered_scaled, -0.2)\n",
    "#waterinAOI_ndwi = water_list[0]\n",
    "\n",
    "#WaterMask = gfc.select(['datamask']).rename('datamask').eq(2)\n",
    "#WaterAOI = AOI_img.mask().updateMask(WaterMask)\n",
    "# unmasked the water (hansen)\n",
    "#unmaskedWaterAOI = AOI_img.unmask().updateMask(WaterAOI.mask().Not()).clip(AOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82bfb2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map.addLayer(waterinAOI_ndwi,{},'check_ndwi')\n",
    "#Map.addLayer(unmaskedWaterAOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93d7b2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ea24d8ff1d442886633a225723881e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-4.887016950796425, 122.69964735710637], controls=(WidgetControl(options=['position', 'transparent…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map.addLayerControl()\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "724d34c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting to tiff\n",
    "if algor_process == 'fcd_galcit' and exporting == True:\n",
    "    list_images = [tiff_result[0], tiff_result[1], tiff_result[2], tiff_result[3], tiff_result[4]]\n",
    "    list_names =  ['Go Zone', 'High Forest Baseline', 'High Baseline no pass 10 years rule', \n",
    "                           'No pass 10 years rule', 'Water (Un-plantable)']\n",
    "    for i in range(len(list_images)):\n",
    "        geemap.ee_export_image_to_drive(\n",
    "            list_images[i], description=f'{AOI_NAME}_{START_DATE}_{END_DATE}_{list_names[i]}', folder=\"JupyterGEE\", scale=30, region=AOI.geometry(),\n",
    "        )\n",
    "        print(f'exported - {list_names[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c637b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the area of an image within the AOI\n",
    "def areas_calculation(img):\n",
    "    # Calculate the total number of pixels in the ROI\n",
    "    area2 = img.reduceRegion(\n",
    "      reducer=ee.Reducer.sum(),\n",
    "      geometry=AOI,\n",
    "      crs=crs_input,\n",
    "      scale=30,\n",
    "      maxPixels=1e13\n",
    "    )\n",
    "\n",
    "    print('area calculated \\n ------')\n",
    "\n",
    "    return ee.Number(area2.get('pixel')).getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b4b51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if (algor_process == 'Sentinel' or algor_process == 'arief_hansen') and calc_areas:\n",
    "    # Create a list of images to analyze\n",
    "    #[goZone_edited,highf_edited,tenyrfl_edited,tenyrule_edited, water_edited]\n",
    "    list_images = [tiff_result[0], tiff_result[1], tiff_result[2], tiff_result[3], tiff_result[4]]\n",
    "\n",
    "    # Select the 'pixel' band and calculate the area of each pixel in hectares\n",
    "    list_areas = [areas_calculation(image.select(['pixel']).multiply(ee.Image.pixelArea()).divide(10000)) for image in list_images]\n",
    "\n",
    "    # Map the areas_calculation function over the list of images to calculate the area of each image\n",
    "    #list_areas = ee.List(selected_band_list_images).map(areas_calculation)\n",
    "    \n",
    "    \n",
    "    data = {'Class': [1, 2, 3, 4,5], \n",
    "            'Name_Class': ['Go Zone', 'High Forest Baseline', 'High Baseline no pass 10 years rule', \n",
    "                           'No pass 10 years rule', 'Water (Un-plantable)'],\n",
    "            'Area_Ha':list_areas}\n",
    "    pd.DataFrame.from_dict(data)\n",
    "    \n",
    "elif (algor_process == 'Hansen' or algor_process == 'hansen_arief') and calc_areas:\n",
    "    # Create a list of images to analyze\n",
    "    #[goZone_edited,highf_edited,tenyrfl_edited,tenyrule_edited, water_edited]\n",
    "    list_images = [GoZoneNoForest_TCL_lessYear_edited, \n",
    "                   GoZone_NoForestSen_lessThreshold_edited, \n",
    "                   Forest_RecentHansen_edited, \n",
    "                   ForestRegenerating_lessYear_edited,\n",
    "                   Forest_Regenerating_lessCC_edited, \n",
    "                   tenYearsRule_edited,\n",
    "                   water_edited\n",
    "                  ]\n",
    "\n",
    "    # Select the 'pixel' band and calculate the area of each pixel in hectares\n",
    "    list_areas = [areas_calculation(image.select(['pixel']).multiply(ee.Image.pixelArea()).divide(10000)) for image in list_images]\n",
    "\n",
    "    # Map the areas_calculation function over the list of images to calculate the area of each image\n",
    "    #list_areas = ee.List(selected_band_list_images).map(areas_calculation)\n",
    "    \n",
    "    data = {'Class': [1,1, 2, 3,3, 4,5], \n",
    "        'Name_Class': ['Go Zone - No Forest (Sentinel) in TCL less year >CC', \n",
    "                       'Go Zone - No Forest (Sentinel) < CC', \n",
    "                       f\"Forest_{END_DATE} - Hansen (No TCL in Forest 2000 until {END_DATE}) to be evaluated\", \n",
    "                       f\"Forest (Sentinel) Regenerating - TCL < 20{year_start_loss}\", \n",
    "                       f\"Forest (Sentinel) CC < {tree_cover_forest}% - Regenerating\",\n",
    "                       \"10 Years Rule - not OK\",\n",
    "                       'Water (Un-plantable)',\n",
    "                      ],\n",
    "        'Area_Ha':list_areas}\n",
    "    pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef891d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3357e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = e_num**(43.2 - 380 * 0.79 - 0.00970 * 0.28 + 0.916* 0.47 + 6.5* 8.67 - 30.6* 3.94 + 259* 0.5)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bdd34e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289f1d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635bfce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d013ad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#TESTING \n",
    "\n",
    "#col_shadow = l9_raw.map(detect_cloud_shadow)\n",
    "\n",
    "# since if we put inside the cloud_mask_oli to iterate map does not work, hence, we only take the image from one best image based on cloud_cover\n",
    "best_image_year = l9_raw.filterBounds(AOI) \\\n",
    "                    .filterDate(START_DATE, END_DATE).filter(ee.Filter.lte('CLOUD_COVER', cloud_cover_threshold)) \\\n",
    "                    .sort('CLOUD_COVER', True).first()\n",
    "\n",
    "#best_image_year = detect_cloud_shadow(best_image_year)\n",
    "#detect_cloud_shadow(best_image_year)\n",
    "\n",
    "AlB10 = ee.Number(best_image_year.get('K1_CONSTANT_BAND_10'))\n",
    "print(AlB10.getInfo())\n",
    "M1B10 = ee.Number(best_image_year.get('RADIANCE_MULT_BAND_10'))\n",
    "K_1 = ee.Number(best_image_year.get('K1_CONSTANT_BAND_10'))\n",
    "K_2 = ee.Number(best_image_year.get('K2_CONSTANT_BAND_10'))\n",
    "A = ee.Number(best_image_year.get('RADIANCE_ADD_BAND_10'))\n",
    "M = ee.Number(best_image_year.get('RADIANCE_MULT_BAND_10'))\n",
    "\n",
    "\n",
    "## TESTING ONE IMAGE FOR TI\n",
    "temp_image = best_image_year.select(['B10'])\n",
    "qa = best_image_year.select('QA_PIXEL')\n",
    "dilated = 1 << 1\n",
    "cirrus = 1 << 2\n",
    "cloud = 1 << 3\n",
    "shadow = 1 << 4\n",
    "mask = qa.bitwiseAnd(dilated).eq(0) \\\n",
    "    .And(qa.bitwiseAnd(cirrus).eq(0)) \\\n",
    "    .And(qa.bitwiseAnd(cloud).eq(0)) \\\n",
    "    .And(qa.bitwiseAnd(shadow).eq(0))\n",
    "\n",
    "radiance = temp_image.updateMask(mask).multiply(M1B10).add(AlB10)\n",
    "        \n",
    "        #K_1 = ee.Number(image.get('K1_CONSTANT_BAND_10'))\n",
    "        #K_2 = ee.Number(image.get('K2_CONSTANT_BAND_10'))\n",
    "        #A = ee.Number(image.get('RADIANCE_ADD_BAND_10'))\n",
    "        #M = ee.Number(image.get('RADIANCE_MULT_BAND_10'))\n",
    "\n",
    "        # Getting the Thermal Index - source??\n",
    "TI = radiance.expression('(K_2) / log((K_1 / TEMP)+1)',{\n",
    "      'K_2': K_2,\n",
    "      'K_1': K_1,\n",
    "      'TEMP':radiance\n",
    "    }\n",
    "  ).rename('TI')\n",
    "\n",
    "TI_norm = normalization_100(TI)                                  \n",
    "                                  \n",
    "Map.addLayer(TI_norm,{'min':0,'max':100},'TI_norm_best_images_TESTING')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c9a748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d73414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d46b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5603b88d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b39f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf6a744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97473daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a4836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10096419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f10f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5950d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 1, 0,0])\n",
    "b = np.array([1, 0, 0,1])\n",
    "c = np.array([0, 0, 1,1])\n",
    "\n",
    "result = a + b + c\n",
    "print(result.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe711603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbceef25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d65e3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed21e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### EXPORTING LANDSAT HANSEN LAST YEAR\n",
    "\n",
    "AOI_NAME = title_map\n",
    "\n",
    "geemap.ee_export_image_to_drive(\n",
    "    LastImageLandsat, description=f'LandsatLast_{END_DATE}_{AOI_NAME}', folder=\"JupyterGEE\", scale=30, region=AOI.geometry(),\n",
    ")\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3739ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPORTING SENTINEL\n",
    "geemap.ee_export_image_to_drive(\n",
    "    s2_sr_median.clip(AOI), description=f'Sentinel_{START_DATE}_{END_DATE}_{AOI_NAME}', folder=\"JupyterGEE\", scale=30, region=AOI.geometry(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839d8f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d62fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dabd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#png_file = './my_map.png'\n",
    "#Map.to_image(filename=png_file, monitor=1)\n",
    "\n",
    "html_file = f'./{title_map}.html'\n",
    "Map.to_html(filename=html_file, title=title_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1278858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d45941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e59b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09130bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {'Class': [1, 2, 3, 4,5], \n",
    "        'Name_Class': ['Go Zone', 'High Forest Baseline', 'High Baseline no pass 10 years rule', \n",
    "                       'No pass 10 years rule', 'Water (Un-plantable)'],\n",
    "        'Area_Ha':list_areas}\n",
    "pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebbf689",
   "metadata": {},
   "outputs": [],
   "source": [
    "AOI_NAME = 'SRA_Sentinel'\n",
    "\n",
    "geemap.ee_export_image_to_drive(\n",
    "    goZone_edited, description=f'GoZone{AOI_NAME}', folder=\"JupyterGEE\", scale=30, region=AOI.geometry(),\n",
    ")\n",
    "\n",
    "geemap.ee_export_image_to_drive(\n",
    "    highf_edited, description=f'HighBaselineForest{AOI_NAME}', folder=\"JupyterGEE\", scale=30, region=AOI.geometry(),\n",
    ")\n",
    "\n",
    "geemap.ee_export_image_to_drive(\n",
    "    tenyrfl_edited, description=f'HighBaseline10yrsForest{AOI_NAME}', folder=\"JupyterGEE\", scale=30, region=AOI.geometry(),\n",
    ")\n",
    "\n",
    "geemap.ee_export_image_to_drive(\n",
    "    tenyrule_edited, description=f'tenyrsForest{AOI_NAME}', folder=\"JupyterGEE\", scale=30, region=AOI.geometry(),\n",
    ")\n",
    "\n",
    "geemap.ee_export_image_to_drive(\n",
    "    water_edited, description=f'Water{AOI_NAME}', folder=\"JupyterGEE\", scale=30, region=AOI.geometry(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1b2fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "goZoneArea = goZone.Not().multiply(ee.Image.pixelArea()).divide(10000) #make the zero number into 1 so that we need '.Not()'\n",
    "\n",
    "# Calculate the total number of pixels in the ROI\n",
    "area2 = goZoneArea.reduceRegion(\n",
    "  reducer=ee.Reducer.sum(),\n",
    "  geometry=AOI,\n",
    "  crs = 'EPSG:32650',\n",
    "  scale=30,\n",
    "  maxPixels=1e13\n",
    ")\n",
    " \n",
    "goZoneAreaHa = ee.Number(\n",
    "  area2.get('first')).getInfo()\n",
    "print(goZoneAreaHa)\n",
    "\n",
    "highBaselineF_Area = highBaselineF.Not().multiply(ee.Image.pixelArea()).divide(10000) #make the zero number into 1 so that we need '.Not()'\n",
    "\n",
    "# Calculate the total number of pixels in the ROI\n",
    "area2_hBF = highBaselineF_Area.reduceRegion(\n",
    "  reducer=ee.Reducer.sum(),\n",
    "  geometry=AOI,\n",
    "  crs = 'EPSG:32650',\n",
    "  scale=30,\n",
    "  maxPixels=1e13\n",
    ")\n",
    " \n",
    "highBaselineF_AreaHa = ee.Number(\n",
    "  area2_hBF.get('nd')).getInfo()\n",
    "print(highBaselineF_AreaHa)\n",
    "\n",
    "waterinAOI_Area = waterinAOI.Not().multiply(ee.Image.pixelArea()).divide(10000) #make the zero number into 1 so that we need '.Not()'\n",
    "\n",
    "# Calculate the total number of pixels in the ROI\n",
    "area2_wtr = waterinAOI_Area.reduceRegion(\n",
    "  reducer=ee.Reducer.sum(),\n",
    "  geometry=AOI,\n",
    "  crs = 'EPSG:32650',\n",
    "  scale=30,\n",
    "  maxPixels=1e13\n",
    ")\n",
    " \n",
    "waterinAOI_AreaHa = ee.Number(\n",
    "  area2_wtr.get('nd')).getInfo()\n",
    "print(waterinAOI_AreaHa)\n",
    "\n",
    "HiForestAndLoss_Area = HiForestAndLoss.Not().multiply(ee.Image.pixelArea()).divide(10000) #make the zero number into 1 so that we need '.Not()'\n",
    "\n",
    "# Calculate the total number of pixels in the ROI\n",
    "area2_hifl = HiForestAndLoss_Area.reduceRegion(\n",
    "  reducer=ee.Reducer.sum(),\n",
    "  geometry=AOI,\n",
    "  crs = 'EPSG:32650',\n",
    "  scale=30,\n",
    "  maxPixels=1e13\n",
    ")\n",
    " \n",
    "HiForestAndLoss_AreaHa = ee.Number(\n",
    "  area2_hifl.get('first')).getInfo()\n",
    "print(HiForestAndLoss_AreaHa)\n",
    "\n",
    "tenYearsRule_Area = tenYearsRule.Not().multiply(ee.Image.pixelArea()).divide(10000) #make the zero number into 1 so that we need '.Not()'\n",
    "\n",
    "# Calculate the total number of pixels in the ROI\n",
    "area2_10yrule = tenYearsRule_Area.reduceRegion(\n",
    "  reducer=ee.Reducer.sum(),\n",
    "  geometry=AOI,\n",
    "  crs = 'EPSG:32650',\n",
    "  scale=30,\n",
    "  maxPixels=1e13\n",
    ")\n",
    " \n",
    "tenYearsRule_AreaHa = ee.Number(\n",
    "  area2_10yrule.get('first')).getInfo()\n",
    "print(tenYearsRule_AreaHa)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a70af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "zoning_cls = zoning_final.select(['Class'])\n",
    "zoning_pixel = zoning_final.select(['pixel']).multiply(ee.Image.pixelArea()).divide(10000)\n",
    "\n",
    "zoning_Area_cls = zoning_pixel.addBands(zoning_cls).reduceRegion(\n",
    "  reducer=ee.Reducer.sum().group(groupField=1),\n",
    "  geometry=AOI,\n",
    "  scale=30,\n",
    "  maxPixels=1e13\n",
    "  )\n",
    "\n",
    "statsFormatted = ee.List(zoning_Area_cls.get('groups')) \\\n",
    "  .map(lambda el: ee.Dictionary(el)) \\\n",
    "  .map(lambda d: [ee.Number(d.get('group')), d.get('sum')])\n",
    "\n",
    "statsDictionary = ee.Dictionary(statsFormatted.flatten())\n",
    "print(statsDictionary)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b32eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Function addition to detect cloud shadows\n",
    "def detect_cloud_shadow(image):\n",
    "    l9_not_raw = l9.filterBounds(AOI) \\\n",
    "                    .filterDate(START_DATE, END_DATE).filter(ee.Filter.lte('CLOUD_COVER', cloud_cover_threshold)) \\\n",
    "                    .sort('CLOUD_COVER', True).first()\n",
    "    \n",
    "    l9_not_raw_b3 = l9_not_raw.select([('SR_B3')]).multiply(0.0000275).add(-0.2)\n",
    "    \n",
    "    shadow_threshold = 0.15\n",
    "\n",
    "    # Create a mask for potential cloud shadows\n",
    "    shadow_mask = l9_not_raw_b3.lt(shadow_threshold)\n",
    "    \n",
    "    # Apply the shadow mask to the image\n",
    "    Map.addLayer(shadow_mask,{'min':0, 'max': 1},'shadow_check')\n",
    "    return image.updateMask(shadow_mask)\n",
    "\n",
    "# Apply cloud shadow detection function to the image collection\n",
    "#shadow_detected_collection = collection.map(detect_cloud_shadow)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
